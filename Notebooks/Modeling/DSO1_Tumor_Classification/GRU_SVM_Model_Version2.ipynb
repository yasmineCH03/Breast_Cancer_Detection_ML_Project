{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mod√®le GRU-SVM pour Classification Binaire\n",
        "\n",
        "Ce notebook impl√©mente l'architecture GRU-SVM d√©crite dans l'article, combinant un r√©seau de neurones r√©current (GRU) avec une machine √† vecteurs de support (SVM).\n",
        "\n",
        "**Auteur:** maramchebbi  \n",
        "**Date:** 2025-11-19  \n",
        "**Plateforme:** Google Colab"
      ],
      "metadata": {
        "id": "title_cell"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Installation et Importation des Biblioth√®ques"
      ],
      "metadata": {
        "id": "imports_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installation des packages n√©cessaires\n",
        "!pip install -q tensorflow scikit-learn numpy pandas matplotlib seaborn"
      ],
      "metadata": {
        "id": "install_packages"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.svm import LinearSVC\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, GRU, Dropout, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuration pour la reproductibilit√©\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"GPU disponible: {tf.config.list_physical_devices('GPU')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Hyperparam√®tres du Mod√®le GRU-SVM\n",
        "\n",
        "Les hyperparam√®tres suivants sont d√©finis selon le **Tableau 1** de l'article."
      ],
      "metadata": {
        "id": "hyperparams_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparam√®tres selon le tableau 1\n",
        "HYPERPARAMETERS = {\n",
        "    'batch_size': 128,\n",
        "    'cell_size': 128,          # Taille de la cellule GRU\n",
        "    'dropout_rate': 0.5,\n",
        "    'epochs': 3000,\n",
        "    'learning_rate': 1e-3,\n",
        "    'norm': 'L2',\n",
        "    'svm_c': 5,                # Param√®tre C du SVM\n",
        "    'validation_split': 0.2,\n",
        "    'early_stopping_patience': 50,\n",
        "    'reduce_lr_patience': 20\n",
        "}\n",
        "\n",
        "# Affichage des hyperparam√®tres\n",
        "print(\"=\"*60)\n",
        "print(\"HYPERPARAM√àTRES DU MOD√àLE GRU-SVM\")\n",
        "print(\"=\"*60)\n",
        "for param, value in HYPERPARAMETERS.items():\n",
        "    print(f\"{param:.<30} {value}\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "hyperparams"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Visualisation des Hyperparam√®tres"
      ],
      "metadata": {
        "id": "viz_hyperparams_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation des hyperparam√®tres\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "fig.suptitle('Hyperparam√®tres du Mod√®le GRU-SVM', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Batch Size\n",
        "ax1 = axes[0, 0]\n",
        "ax1.bar(['Batch Size'], [HYPERPARAMETERS['batch_size']], color='#2E86AB')\n",
        "ax1.set_ylabel('Valeur')\n",
        "ax1.set_title('Batch Size')\n",
        "ax1.text(0, HYPERPARAMETERS['batch_size']/2, str(HYPERPARAMETERS['batch_size']), \n",
        "         ha='center', va='center', fontsize=14, color='white', fontweight='bold')\n",
        "\n",
        "# Cell Size (GRU)\n",
        "ax2 = axes[0, 1]\n",
        "ax2.bar(['Cell Size'], [HYPERPARAMETERS['cell_size']], color='#A23B72')\n",
        "ax2.set_ylabel('Valeur')\n",
        "ax2.set_title('Taille de la Cellule GRU')\n",
        "ax2.text(0, HYPERPARAMETERS['cell_size']/2, str(HYPERPARAMETERS['cell_size']), \n",
        "         ha='center', va='center', fontsize=14, color='white', fontweight='bold')\n",
        "\n",
        "# Dropout Rate\n",
        "ax3 = axes[0, 2]\n",
        "ax3.bar(['Dropout Rate'], [HYPERPARAMETERS['dropout_rate']], color='#F18F01')\n",
        "ax3.set_ylabel('Taux')\n",
        "ax3.set_title('Taux de Dropout')\n",
        "ax3.set_ylim([0, 1])\n",
        "ax3.text(0, HYPERPARAMETERS['dropout_rate']/2, f\"{HYPERPARAMETERS['dropout_rate']:.1f}\", \n",
        "         ha='center', va='center', fontsize=14, color='white', fontweight='bold')\n",
        "\n",
        "# Epochs\n",
        "ax4 = axes[1, 0]\n",
        "ax4.bar(['Epochs'], [HYPERPARAMETERS['epochs']], color='#C73E1D')\n",
        "ax4.set_ylabel('Nombre')\n",
        "ax4.set_title('Nombre d\\'Epochs')\n",
        "ax4.text(0, HYPERPARAMETERS['epochs']/2, str(HYPERPARAMETERS['epochs']), \n",
        "         ha='center', va='center', fontsize=14, color='white', fontweight='bold')\n",
        "\n",
        "# Learning Rate\n",
        "ax5 = axes[1, 1]\n",
        "ax5.bar(['Learning Rate'], [HYPERPARAMETERS['learning_rate']], color='#6A994E')\n",
        "ax5.set_ylabel('Valeur')\n",
        "ax5.set_title('Taux d\\'Apprentissage')\n",
        "ax5.set_yscale('log')\n",
        "ax5.text(0, HYPERPARAMETERS['learning_rate'], f\"{HYPERPARAMETERS['learning_rate']}\", \n",
        "         ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
        "\n",
        "# SVM C Parameter\n",
        "ax6 = axes[1, 2]\n",
        "ax6.bar(['SVM C'], [HYPERPARAMETERS['svm_c']], color='#BC4B51')\n",
        "ax6.set_ylabel('Valeur')\n",
        "ax6.set_title('Param√®tre C du SVM (R√©gularisation)')\n",
        "ax6.text(0, HYPERPARAMETERS['svm_c']/2, str(HYPERPARAMETERS['svm_c']), \n",
        "         ha='center', va='center', fontsize=14, color='white', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Tableau r√©capitulatif\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TABLEAU R√âCAPITULATIF DES HYPERPARAM√àTRES\")\n",
        "print(\"=\"*60)\n",
        "df_params = pd.DataFrame({\n",
        "    'Hyperparam√®tre': list(HYPERPARAMETERS.keys()),\n",
        "    'Valeur': list(HYPERPARAMETERS.values())\n",
        "})\n",
        "print(df_params.to_string(index=False))\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "viz_hyperparams"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Architecture du Mod√®le GRU-SVM\n",
        "\n",
        "### √âquations du GRU:\n",
        "\n",
        "**Update Gate:**\n",
        "$$z_t = \\sigma(W_z \\cdot [h_{t-1}, x_t])$$\n",
        "\n",
        "**Reset Gate:**\n",
        "$$r_t = \\sigma(W_r \\cdot [h_{t-1}, x_t])$$\n",
        "\n",
        "**Candidate Hidden State:**\n",
        "$$\\tilde{h}_t = \\tanh(W \\cdot [r_t * h_{t-1}, x_t])$$\n",
        "\n",
        "**New Hidden State:**\n",
        "$$h_t = (1 - z_t) * h_{t-1} + z_t * \\tilde{h}_t$$\n",
        "\n",
        "### Fonction de D√©cision:\n",
        "$$y' = \\text{argmax}(\\text{sign}(wx + b))$$"
      ],
      "metadata": {
        "id": "architecture_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUSVM:\n",
        "    \"\"\"\n",
        "    Architecture GRU-SVM pour classification binaire.\n",
        "    \n",
        "    Le mod√®le combine:\n",
        "    - Une couche GRU pour l'extraction de caract√©ristiques temporelles\n",
        "    - Un SVM lin√©aire (L2-SVM) pour la classification finale\n",
        "    \n",
        "    √âquations du GRU:\n",
        "    - z = œÉ(W_z ¬∑ [h_{t-1}, x_t])           (update gate)\n",
        "    - r = œÉ(W_r ¬∑ [h_{t-1}, x_t])           (reset gate)\n",
        "    - hÃÉ_t = tanh(W ¬∑ [r_t * h_{t-1}, x_t]) (candidate value)\n",
        "    - h_t = (1 - z_t) * h_{t-1} + z_t * hÃÉ_t (new hidden state)\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, input_shape, hyperparams):\n",
        "        self.input_shape = input_shape\n",
        "        self.hyperparams = hyperparams\n",
        "        self.gru_model = None\n",
        "        self.svm_model = None\n",
        "        self.scaler = StandardScaler()\n",
        "        self.history = None\n",
        "        \n",
        "    def build_gru_feature_extractor(self):\n",
        "        \"\"\"\n",
        "        Construit le r√©seau GRU pour l'extraction de caract√©ristiques.\n",
        "        \"\"\"\n",
        "        inputs = Input(shape=self.input_shape, name='input_layer')\n",
        "        \n",
        "        # Couche GRU avec return_sequences=False pour obtenir le dernier √©tat cach√©\n",
        "        x = GRU(\n",
        "            units=self.hyperparams['cell_size'],\n",
        "            activation='tanh',\n",
        "            recurrent_activation='sigmoid',\n",
        "            use_bias=True,\n",
        "            kernel_initializer='glorot_uniform',\n",
        "            recurrent_initializer='orthogonal',\n",
        "            return_sequences=False,\n",
        "            name='gru_layer'\n",
        "        )(inputs)\n",
        "        \n",
        "        # Dropout pour r√©gularisation\n",
        "        x = Dropout(self.hyperparams['dropout_rate'], name='dropout_layer')(x)\n",
        "        \n",
        "        # Le GRU model retourne les caract√©ristiques (h_t)\n",
        "        self.gru_model = Model(inputs=inputs, outputs=x, name='GRU_Feature_Extractor')\n",
        "        \n",
        "        return self.gru_model\n",
        "    \n",
        "    def compile_gru(self):\n",
        "        \"\"\"\n",
        "        Compile le mod√®le GRU avec l'optimiseur Adam.\n",
        "        \"\"\"\n",
        "        optimizer = Adam(learning_rate=self.hyperparams['learning_rate'])\n",
        "        \n",
        "        # Pour l'entra√Ænement du GRU seul (si n√©cessaire)\n",
        "        self.gru_model.compile(\n",
        "            optimizer=optimizer,\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "    \n",
        "    def train_gru(self, X_train, y_train, X_val=None, y_val=None):\n",
        "        \"\"\"\n",
        "        Entra√Æne le mod√®le GRU.\n",
        "        \"\"\"\n",
        "        callbacks = [\n",
        "            EarlyStopping(\n",
        "                monitor='val_loss',\n",
        "                patience=self.hyperparams['early_stopping_patience'],\n",
        "                restore_best_weights=True,\n",
        "                verbose=1\n",
        "            ),\n",
        "            ReduceLROnPlateau(\n",
        "                monitor='val_loss',\n",
        "                factor=0.5,\n",
        "                patience=self.hyperparams['reduce_lr_patience'],\n",
        "                min_lr=1e-7,\n",
        "                verbose=1\n",
        "            )\n",
        "        ]\n",
        "        \n",
        "        validation_data = (X_val, y_val) if X_val is not None else None\n",
        "        \n",
        "        self.history = self.gru_model.fit(\n",
        "            X_train, y_train,\n",
        "            batch_size=self.hyperparams['batch_size'],\n",
        "            epochs=self.hyperparams['epochs'],\n",
        "            validation_data=validation_data,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "        \n",
        "        return self.history\n",
        "    \n",
        "    def extract_features(self, X):\n",
        "        \"\"\"\n",
        "        Extrait les caract√©ristiques en utilisant le GRU entra√Æn√©.\n",
        "        Retourne h_t (le dernier √©tat cach√© du GRU).\n",
        "        \"\"\"\n",
        "        return self.gru_model.predict(X, batch_size=self.hyperparams['batch_size'])\n",
        "    \n",
        "    def train_svm(self, X_train, y_train):\n",
        "        \"\"\"\n",
        "        Entra√Æne le SVM L2 sur les caract√©ristiques extraites par le GRU.\n",
        "        \n",
        "        Fonction de d√©cision: f(x) = argmax(sign(wx + b))\n",
        "        Avec w et b appris par le L2-SVM.\n",
        "        \"\"\"\n",
        "        # Extraire les caract√©ristiques avec le GRU\n",
        "        print(\"\\nExtraction des caract√©ristiques d'entra√Ænement avec GRU...\")\n",
        "        features_train = self.extract_features(X_train)\n",
        "        \n",
        "        # Normalisation des caract√©ristiques\n",
        "        features_train_scaled = self.scaler.fit_transform(features_train)\n",
        "        \n",
        "        # Entra√Ænement du SVM avec norme L2\n",
        "        print(\"Entra√Ænement du SVM L2...\")\n",
        "        self.svm_model = LinearSVC(\n",
        "            C=self.hyperparams['svm_c'],\n",
        "            penalty='l2',  # R√©gularisation L2\n",
        "            loss='squared_hinge',  # Loss function du L2-SVM\n",
        "            max_iter=5000,\n",
        "            random_state=42,\n",
        "            verbose=1\n",
        "        )\n",
        "        \n",
        "        # Convertir les labels en -1 et +1 pour le SVM\n",
        "        y_train_svm = np.where(y_train == 0, -1, 1)\n",
        "        \n",
        "        self.svm_model.fit(features_train_scaled, y_train_svm)\n",
        "        \n",
        "        print(\"Entra√Ænement du SVM termin√©!\")\n",
        "        \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Pr√©dit les classes en utilisant l'architecture GRU-SVM compl√®te.\n",
        "        \n",
        "        y' = argmax(sign(wx + b))\n",
        "        \"\"\"\n",
        "        # Extraire les caract√©ristiques\n",
        "        features = self.extract_features(X)\n",
        "        features_scaled = self.scaler.transform(features)\n",
        "        \n",
        "        # Pr√©dire avec le SVM\n",
        "        predictions = self.svm_model.predict(features_scaled)\n",
        "        \n",
        "        # Convertir -1, +1 en 0, 1\n",
        "        predictions = np.where(predictions == -1, 0, 1)\n",
        "        \n",
        "        return predictions\n",
        "    \n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"\n",
        "        Retourne les scores de d√©cision du SVM.\n",
        "        \"\"\"\n",
        "        features = self.extract_features(X)\n",
        "        features_scaled = self.scaler.transform(features)\n",
        "        \n",
        "        # Decision function donne les scores\n",
        "        scores = self.svm_model.decision_function(features_scaled)\n",
        "        \n",
        "        return scores\n",
        "    \n",
        "    def summary(self):\n",
        "        \"\"\"\n",
        "        Affiche le r√©sum√© de l'architecture.\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"ARCHITECTURE GRU-SVM\")\n",
        "        print(\"=\"*60)\n",
        "        self.gru_model.summary()\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"SVM CLASSIFIER\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"Kernel: Linear (L2-SVM)\")\n",
        "        print(f\"C parameter: {self.hyperparams['svm_c']}\")\n",
        "        print(f\"Penalty: L2\")\n",
        "        print(\"=\"*60)"
      ],
      "metadata": {
        "id": "architecture"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. G√©n√©ration de Donn√©es Synth√©tiques (Exemple)\n",
        "\n",
        "‚ö†Ô∏è **Note importante:** Pour votre cas r√©el, remplacez cette section par le chargement de vos donn√©es de diagnostic du cancer."
      ],
      "metadata": {
        "id": "data_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_synthetic_data(n_samples=38400, n_timesteps=50, n_features=10):\n",
        "    \"\"\"\n",
        "    G√©n√®re des donn√©es synth√©tiques pour tester le mod√®le.\n",
        "    \n",
        "    Pour votre cas r√©el, remplacez cette fonction par le chargement\n",
        "    de vos donn√©es de diagnostic du cancer.\n",
        "    \"\"\"\n",
        "    print(f\"\\nG√©n√©ration de {n_samples} √©chantillons synth√©tiques...\")\n",
        "    print(f\"Dimensions: ({n_timesteps} timesteps, {n_features} features)\")\n",
        "    \n",
        "    # G√©n√©ration de s√©quences temporelles\n",
        "    X = np.random.randn(n_samples, n_timesteps, n_features)\n",
        "    \n",
        "    # G√©n√©ration de labels binaires (0: benign, 1: malignant)\n",
        "    # Ajouter une certaine structure pour que le mod√®le puisse apprendre\n",
        "    y = (np.mean(X[:, :, 0], axis=1) + np.std(X[:, :, 1], axis=1) > 0).astype(int)\n",
        "    \n",
        "    print(f\"Distribution des classes:\")\n",
        "    print(f\"  Classe 0 (Benign): {np.sum(y == 0)} ({np.mean(y == 0)*100:.2f}%)\")\n",
        "    print(f\"  Classe 1 (Malignant): {np.sum(y == 1)} ({np.mean(y == 1)*100:.2f}%)\")\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "# G√©n√©ration des donn√©es\n",
        "X, y = generate_synthetic_data(n_samples=38400, n_timesteps=50, n_features=10)\n",
        "\n",
        "# Division des donn√©es\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "print(f\"\\nTaille des ensembles:\")\n",
        "print(f\"  Train: {X_train.shape[0]} samples\")\n",
        "print(f\"  Validation: {X_val.shape[0]} samples\")\n",
        "print(f\"  Test: {X_test.shape[0]} samples\")"
      ],
      "metadata": {
        "id": "data_generation"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Construction et Entra√Ænement du Mod√®le"
      ],
      "metadata": {
        "id": "training_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciation du mod√®le\n",
        "input_shape = (X_train.shape[1], X_train.shape[2])  # (timesteps, features)\n",
        "\n",
        "gru_svm_model = GRUSVM(input_shape=input_shape, hyperparams=HYPERPARAMETERS)\n",
        "\n",
        "# Construction de l'extracteur de caract√©ristiques GRU\n",
        "gru_svm_model.build_gru_feature_extractor()\n",
        "gru_svm_model.compile_gru()\n",
        "\n",
        "# Affichage de l'architecture\n",
        "gru_svm_model.summary()"
      ],
      "metadata": {
        "id": "model_build"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entra√Ænement du GRU\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PHASE 1: ENTRA√éNEMENT DU GRU\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "history = gru_svm_model.train_gru(\n",
        "    X_train, y_train,\n",
        "    X_val, y_val\n",
        ")"
      ],
      "metadata": {
        "id": "train_gru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Visualisation de l'Entra√Ænement du GRU"
      ],
      "metadata": {
        "id": "viz_training_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation de la courbe d'apprentissage\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Loss\n",
        "axes[0].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
        "axes[0].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
        "axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "axes[0].set_ylabel('Loss', fontsize=12)\n",
        "axes[0].set_title('Courbe de Loss du GRU', fontsize=14, fontweight='bold')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Accuracy\n",
        "axes[1].plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
        "axes[1].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
        "axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "axes[1].set_ylabel('Accuracy', fontsize=12)\n",
        "axes[1].set_title('Courbe d\\'Accuracy du GRU', fontsize=14, fontweight='bold')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "viz_training"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entra√Ænement du SVM sur les caract√©ristiques GRU\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PHASE 2: ENTRA√éNEMENT DU SVM L2\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "gru_svm_model.train_svm(X_train, y_train)"
      ],
      "metadata": {
        "id": "train_svm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. √âvaluation du Mod√®le"
      ],
      "metadata": {
        "id": "eval_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pr√©dictions sur l'ensemble de test\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"√âVALUATION SUR L'ENSEMBLE DE TEST\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "y_pred = gru_svm_model.predict(X_test)\n",
        "\n",
        "# Calcul des m√©triques\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Calcul des m√©triques d√©taill√©es\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "tpr = tp / (tp + fn)  # True Positive Rate (Sensitivity)\n",
        "tnr = tn / (tn + fp)  # True Negative Rate (Specificity)\n",
        "fpr = fp / (fp + tn)  # False Positive Rate\n",
        "fnr = fn / (fn + tp)  # False Negative Rate\n",
        "\n",
        "print(f\"\\nAccuracy: {accuracy*100:.2f}%\")\n",
        "print(f\"\\nM√©triques d√©taill√©es:\")\n",
        "print(f\"  TPR (True Positive Rate):  {tpr*100:.2f}%\")\n",
        "print(f\"  TNR (True Negative Rate):  {tnr*100:.2f}%\")\n",
        "print(f\"  FPR (False Positive Rate): {fpr*100:.2f}%\")\n",
        "print(f\"  FNR (False Negative Rate): {fnr*100:.2f}%\")\n",
        "\n",
        "print(\"\\n\" + classification_report(y_test, y_pred, \n",
        "                                    target_names=['Benign', 'Malignant']))"
      ],
      "metadata": {
        "id": "evaluation"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Visualisation de la Matrice de Confusion"
      ],
      "metadata": {
        "id": "confusion_matrix_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation de la matrice de confusion\n",
        "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
        "\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=['Benign', 'Malignant'],\n",
        "            yticklabels=['Benign', 'Malignant'],\n",
        "            cbar_kws={'label': 'Count'},\n",
        "            ax=ax)\n",
        "\n",
        "ax.set_xlabel('Classe Pr√©dite', fontsize=12)\n",
        "ax.set_ylabel('Classe R√©elle', fontsize=12)\n",
        "ax.set_title('Matrice de Confusion - Mod√®le GRU-SVM', fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "confusion_matrix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Comparaison des R√©sultats avec le Tableau 2"
      ],
      "metadata": {
        "id": "comparison_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# R√©sultats attendus selon le tableau 2\n",
        "expected_results = {\n",
        "    'Model': 'GRU-SVM',\n",
        "    'Accuracy': 93.75,\n",
        "    'Data points': 384000,\n",
        "    'Epochs': 3000,\n",
        "    'FPR': 16.67,\n",
        "    'FNR': 0,\n",
        "    'TPR': 100,\n",
        "    'TNR': 83.33\n",
        "}\n",
        "\n",
        "# R√©sultats obtenus\n",
        "obtained_results = {\n",
        "    'Model': 'GRU-SVM (Implementation)',\n",
        "    'Accuracy': accuracy * 100,\n",
        "    'Data points': X_train.shape[0],\n",
        "    'Epochs': len(history.history['loss']),\n",
        "    'FPR': fpr * 100,\n",
        "    'FNR': fnr * 100,\n",
        "    'TPR': tpr * 100,\n",
        "    'TNR': tnr * 100\n",
        "}\n",
        "\n",
        "# Tableau de comparaison\n",
        "comparison_df = pd.DataFrame([expected_results, obtained_results])\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COMPARAISON DES R√âSULTATS\")\n",
        "print(\"=\"*60)\n",
        "print(comparison_df.to_string(index=False))\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "comparison"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation comparative\n",
        "metrics = ['Accuracy', 'TPR', 'TNR', 'FPR', 'FNR']\n",
        "expected_values = [expected_results[m] for m in metrics]\n",
        "obtained_values = [obtained_results[m] for m in metrics]\n",
        "\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "bars1 = ax.bar(x - width/2, expected_values, width, label='Attendu (Article)', color='#2E86AB')\n",
        "bars2 = ax.bar(x + width/2, obtained_values, width, label='Obtenu (Implementation)', color='#F18F01')\n",
        "\n",
        "ax.set_ylabel('Pourcentage (%)', fontsize=12)\n",
        "ax.set_title('Comparaison des M√©triques: GRU-SVM', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics)\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Ajouter les valeurs sur les barres\n",
        "for bars in [bars1, bars2]:\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.annotate(f'{height:.1f}%',\n",
        "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                    xytext=(0, 3),\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "comparison_viz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Sauvegarde du Mod√®le"
      ],
      "metadata": {
        "id": "save_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sauvegarder le mod√®le GRU\n",
        "print(\"\\nSauvegarde des mod√®les...\")\n",
        "gru_svm_model.gru_model.save('gru_feature_extractor.h5')\n",
        "print(\"‚úì Mod√®le GRU sauvegard√©: gru_feature_extractor.h5\")\n",
        "\n",
        "# Sauvegarder le SVM avec pickle\n",
        "import pickle\n",
        "with open('svm_classifier.pkl', 'wb') as f:\n",
        "    pickle.dump(gru_svm_model.svm_model, f)\n",
        "print(\"‚úì Mod√®le SVM sauvegard√©: svm_classifier.pkl\")\n",
        "\n",
        "# Sauvegarder le scaler\n",
        "with open('feature_scaler.pkl', 'wb') as f:\n",
        "    pickle.dump(gru_svm_model.scaler, f)\n",
        "print(\"‚úì Scaler sauvegard√©: feature_scaler.pkl\")\n",
        "\n",
        "print(\"\\nTous les mod√®les ont √©t√© sauvegard√©s avec succ√®s!\")"
      ],
      "metadata": {
        "id": "save_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. T√©l√©chargement des Mod√®les (Google Colab)"
      ],
      "metadata": {
        "id": "download_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# T√©l√©charger les fichiers sauvegard√©s dans Google Colab\n",
        "from google.colab import files\n",
        "\n",
        "print(\"T√©l√©chargement des mod√®les...\")\n",
        "files.download('gru_feature_extractor.h5')\n",
        "files.download('svm_classifier.pkl')\n",
        "files.download('feature_scaler.pkl')\n",
        "print(\"T√©l√©chargement termin√©!\")"
      ],
      "metadata": {
        "id": "download_models"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. Chargement et Utilisation du Mod√®le"
      ],
      "metadata": {
        "id": "load_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemple de chargement du mod√®le\n",
        "def load_gru_svm_model():\n",
        "    \"\"\"\n",
        "    Charge le mod√®le GRU-SVM sauvegard√©.\n",
        "    \"\"\"\n",
        "    from tensorflow.keras.models import load_model\n",
        "    import pickle\n",
        "    \n",
        "    # Charger le GRU\n",
        "    gru_model = load_model('gru_feature_extractor.h5')\n",
        "    \n",
        "    # Charger le SVM\n",
        "    with open('svm_classifier.pkl', 'rb') as f:\n",
        "        svm_model = pickle.load(f)\n",
        "    \n",
        "    # Charger le scaler\n",
        "    with open('feature_scaler.pkl', 'rb') as f:\n",
        "        scaler = pickle.load(f)\n",
        "    \n",
        "    return gru_model, svm_model, scaler\n",
        "\n",
        "# Exemple d'utilisation\n",
        "# gru_model, svm_model, scaler = load_gru_svm_model()\n",
        "print(\"Fonction de chargement du mod√®le d√©finie!\")"
      ],
      "metadata": {
        "id": "load_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14. Instructions pour Utiliser vos Propres Donn√©es\n",
        "\n",
        "Pour utiliser ce notebook avec vos donn√©es de diagnostic du cancer:\n",
        "\n",
        "### 1. Pr√©parez vos donn√©es\n",
        "\n",
        "```python\n",
        "# Upload votre fichier de donn√©es sur Google Colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Chargez vos donn√©es (exemple avec CSV)\n",
        "import pandas as pd\n",
        "df = pd.read_csv('votre_fichier.csv')\n",
        "\n",
        "# Pr√©parez X et y\n",
        "# X doit avoir la forme: (n_samples, n_timesteps, n_features)\n",
        "# y doit avoir la forme: (n_samples,) avec des valeurs 0 ou 1\n",
        "```\n",
        "\n",
        "### 2. Format des donn√©es\n",
        "\n",
        "- **X (Features)**: Array 3D de forme `(n_samples, n_timesteps, n_features)`\n",
        "  - `n_samples`: Nombre total d'√©chantillons\n",
        "  - `n_timesteps`: Nombre de pas de temps (s√©quence)\n",
        "  - `n_features`: Nombre de caract√©ristiques par pas de temps\n",
        "\n",
        "- **y (Labels)**: Array 1D de forme `(n_samples,)`\n",
        "  - `0`: B√©nin (Benign)\n",
        "  - `1`: Malin (Malignant)\n",
        "\n",
        "### 3. Remplacez la section \"G√©n√©ration de Donn√©es Synth√©tiques\"\n",
        "\n",
        "Supprimez ou commentez la cellule de g√©n√©ration de donn√©es synth√©tiques et utilisez vos propres donn√©es."
      ],
      "metadata": {
        "id": "instructions_header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 15. Conclusion\n",
        "\n",
        "Ce notebook impl√©mente l'architecture **GRU-SVM** pour la classification binaire du cancer.\n",
        "\n",
        "### Points cl√©s:\n",
        "\n",
        "1. ‚úÖ **Architecture hybride**: GRU (extraction) + SVM (classification)\n",
        "2. ‚úÖ **Hyperparam√®tres optimis√©s**: Selon le Tableau 1\n",
        "3. ‚úÖ **R√©gularisation**: Dropout (0.5) et norme L2\n",
        "4. ‚úÖ **Visualisations compl√®tes**: Hyperparam√®tres, courbes d'apprentissage, m√©triques\n",
        "5. ‚úÖ **Sauvegarde/Chargement**: Mod√®les r√©utilisables\n",
        "\n",
        "### √âquations impl√©ment√©es:\n",
        "\n",
        "**GRU:**\n",
        "- $z_t = \\sigma(W_z \\cdot [h_{t-1}, x_t])$ (update gate)\n",
        "- $r_t = \\sigma(W_r \\cdot [h_{t-1}, x_t])$ (reset gate)\n",
        "- $\\tilde{h}_t = \\tanh(W \\cdot [r_t * h_{t-1}, x_t])$ (candidate)\n",
        "- $h_t = (1 - z_t) * h_{t-1} + z_t * \\tilde{h}_t$ (new state)\n",
        "\n",
        "**SVM:**\n",
        "- $y' = \\text{argmax}(\\text{sign}(wx + b))$ (decision function)\n",
        "\n",
        "### Performance attendue (selon Tableau 2):\n",
        "\n",
        "- **Accuracy**: 93.75%\n",
        "- **TPR**: 100%\n",
        "- **TNR**: 83.33%\n",
        "- **FPR**: 16.67%\n",
        "- **FNR**: 0%\n",
        "\n",
        "---\n",
        "\n",
        "**Cr√©√© par:** maramchebbi  \n",
        "**Date:** 2025-11-19  \n",
        "**Plateforme:** Google Colab\n",
        "\n",
        "üìä **Notebook pr√™t pour l'entra√Ænement sur GPU!**"
      ],
      "metadata": {
        "id": "conclusion"
      }
    }
  ]
}