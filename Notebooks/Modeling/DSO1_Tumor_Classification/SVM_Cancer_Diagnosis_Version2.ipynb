{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title_cell"
      },
      "source": [
        "# Support Vector Machine (SVM) pour Classification Binaire - Diagnostic du Cancer\n",
        "\n",
        "Ce notebook impl√©mente les mod√®les **L1-SVM** et **L2-SVM** pour le diagnostic du cancer (B√©nin vs Malin).\n",
        "\n",
        "## √âquations du SVM\n",
        "\n",
        "### L1-SVM (Primal Form):\n",
        "$$\\min_{w,b} \\frac{1}{p}w^T w + C \\sum_{i=1}^{p} \\max(0, 1 - y_i'(w \\cdot x_i + b))$$\n",
        "\n",
        "### L2-SVM:\n",
        "$$\\min_{w,b} \\frac{1}{p}||w||_2^2 + C \\sum_{i=1}^{p} \\max(0, 1 - y_i'(w \\cdot x_i + b))^2$$\n",
        "\n",
        "O√π:\n",
        "- $w$ : vecteur de poids\n",
        "- $b$ : biais\n",
        "- $C$ : param√®tre de r√©gularisation\n",
        "- $y_i' \\in \\{-1, +1\\}$ : labels\n",
        "\n",
        "**Auteur**: maramchebbi  \n",
        "**Date**: 2025-11-19"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imports_header"
      },
      "source": [
        "## 1. Installation et Importation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_packages"
      },
      "outputs": [],
      "source": [
        "!pip install -q scikit-learn numpy pandas matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "np.random.seed(42)\n",
        "print(\"‚úÖ Biblioth√®ques import√©es!!!! avec succ√®s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_loading_header"
      },
      "source": [
        "## 2. Chargement des Donn√©es"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload_file"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "print(\"üìÅ Veuillez uploader votre fichier data.csv\")\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_data"
      },
      "outputs": [],
      "source": [
        "# Charger les donn√©es\n",
        "data = pd.read_csv('data.csv')\n",
        "\n",
        "print(\"üìä Dimensions du dataset:\", data.shape)\n",
        "print(\"\\nüìã Premi√®res lignes:\")\n",
        "print(data.head())\n",
        "\n",
        "print(\"\\nüìà Distribution des diagnostics:\")\n",
        "print(data['diagnosis'].value_counts())\n",
        "print(\"\\nüìä Pourcentage:\")\n",
        "print(data['diagnosis'].value_counts(normalize=True) * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_prep_header"
      },
      "source": [
        "## 3. Pr√©paration des Donn√©es"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prepare_data"
      },
      "outputs": [],
      "source": [
        "# Nettoyage et pr√©paration\n",
        "# 1. Supprimer les colonnes inutiles\n",
        "if 'id' in data.columns:\n",
        "    data = data.drop('id', axis=1)\n",
        "\n",
        "# Supprimer les colonnes vides (Unnamed)\n",
        "unnamed_cols = [col for col in data.columns if 'Unnamed' in col]\n",
        "if unnamed_cols:\n",
        "    print(f\"‚ö†Ô∏è Suppression des colonnes vides: {unnamed_cols}\")\n",
        "    data = data.drop(columns=unnamed_cols)\n",
        "\n",
        "# 2. Encoder le diagnostic (M=1, B=0)\n",
        "le = LabelEncoder()\n",
        "data['diagnosis'] = le.fit_transform(data['diagnosis'])\n",
        "print(f\"\\n‚úÖ Encodage: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n",
        "\n",
        "# 3. S√©parer features et cible\n",
        "X = data.drop('diagnosis', axis=1).values\n",
        "y = data['diagnosis'].values\n",
        "\n",
        "# Convertir y en {-1, +1} pour le SVM\n",
        "y_svm = np.where(y == 0, -1, 1)\n",
        "\n",
        "print(f\"\\nüìä Dimensions:\")\n",
        "print(f\"  X: {X.shape}\")\n",
        "print(f\"  y: {y.shape}\")\n",
        "print(f\"  Classes SVM: {np.unique(y_svm)}\")\n",
        "\n",
        "# 4. Normalisation\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(f\"\\n‚úÖ Donn√©es normalis√©es\")\n",
        "print(f\"  Mean: {X_scaled.mean():.4f}\")\n",
        "print(f\"  Std: {X_scaled.std():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "split_data"
      },
      "outputs": [],
      "source": [
        "# 5. Division train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y_svm, test_size=0.2, random_state=42, stratify=y_svm\n",
        ")\n",
        "\n",
        "print(f\"\\nüìä Taille des ensembles:\")\n",
        "print(f\"  Train: {X_train.shape[0]} samples ({np.sum(y_train==-1)} B√©nin, {np.sum(y_train==1)} Malin)\")\n",
        "print(f\"  Test: {X_test.shape[0]} samples ({np.sum(y_test==-1)} B√©nin, {np.sum(y_test==1)} Malin)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyperparams_header"
      },
      "source": [
        "## 4. Hyperparam√®tres selon le Tableau 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyperparams"
      },
      "outputs": [],
      "source": [
        "# Hyperparam√®tres pour SVM\n",
        "HYPERPARAMETERS = {\n",
        "    'batch_size': 128,\n",
        "    'epochs': 3000,\n",
        "    'learning_rate': 1e-3,\n",
        "    'norm': 'L2',\n",
        "    'svm_c': 5,  # Param√®tre C principal\n",
        "    'max_iter': 5000\n",
        "}\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"HYPERPARAM√àTRES DES MOD√àLES SVM\")\n",
        "print(\"=\"*60)\n",
        "for param, value in HYPERPARAMETERS.items():\n",
        "    print(f\"{param:.<30} {value}\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viz_hyperparams_header"
      },
      "source": [
        "## 5. Visualisation des Hyperparam√®tres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viz_hyperparams"
      },
      "outputs": [],
      "source": [
        "# Visualisation\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "fig.suptitle('Hyperparam√®tres des Mod√®les SVM', fontsize=16, fontweight='bold')\n",
        "\n",
        "# SVM C\n",
        "axes[0].bar(['SVM C'], [HYPERPARAMETERS['svm_c']], color='#2E86AB')\n",
        "axes[0].set_ylabel('Valeur')\n",
        "axes[0].set_title('Param√®tre C\\n(R√©gularisation)')\n",
        "axes[0].text(0, HYPERPARAMETERS['svm_c']/2, str(HYPERPARAMETERS['svm_c']), \n",
        "             ha='center', va='center', fontsize=14, color='white', fontweight='bold')\n",
        "\n",
        "# Max Iterations\n",
        "axes[1].bar(['Max Iter'], [HYPERPARAMETERS['max_iter']], color='#F18F01')\n",
        "axes[1].set_ylabel('Nombre')\n",
        "axes[1].set_title('It√©rations Maximales')\n",
        "axes[1].text(0, HYPERPARAMETERS['max_iter']/2, str(HYPERPARAMETERS['max_iter']), \n",
        "             ha='center', va='center', fontsize=14, color='white', fontweight='bold')\n",
        "\n",
        "# Norm Type\n",
        "norm_map = {'L1': 1, 'L2': 2}\n",
        "axes[2].bar(['Norm'], [norm_map[HYPERPARAMETERS['norm']]], color='#6A994E')\n",
        "axes[2].set_ylabel('Type')\n",
        "axes[2].set_title('Type de Norme')\n",
        "axes[2].set_ylim([0, 3])\n",
        "axes[2].text(0, 1, HYPERPARAMETERS['norm'], \n",
        "             ha='center', va='center', fontsize=14, color='white', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "models_header"
      },
      "source": [
        "## 6. Impl√©mentation des Mod√®les SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svm_class"
      },
      "outputs": [],
      "source": [
        "class SVMModels:\n",
        "    \"\"\"\n",
        "    Classe pour entra√Æner et √©valuer les mod√®les SVM.\n",
        "    \n",
        "    Impl√©mente:\n",
        "    - L1-SVM: avec norme L1 (penalty='l1')\n",
        "    - L2-SVM: avec norme L2 (penalty='l2')\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, C=5, max_iter=5000):\n",
        "        self.C = C\n",
        "        self.max_iter = max_iter\n",
        "        self.models = {}\n",
        "        self.results = {}\n",
        "    \n",
        "    def train_l1_svm(self, X_train, y_train):\n",
        "        \"\"\"\n",
        "        Entra√Æne le L1-SVM.\n",
        "        \n",
        "        √âquation (19):\n",
        "        min (1/p)w^T w + C * sum(max(0, 1 - y_i'(wx_i + b)))\n",
        "        \"\"\"\n",
        "        print(\"\\nüîÑ Entra√Ænement du L1-SVM...\")\n",
        "        print(f\"  Param√®tres: C={self.C}, penalty='l1', loss='squared_hinge'\")\n",
        "        \n",
        "        # L1-SVM avec dual=False (forme primale)\n",
        "        self.models['L1-SVM'] = LinearSVC(\n",
        "            C=self.C,\n",
        "            penalty='l1',\n",
        "            loss='squared_hinge',\n",
        "            dual=False,  # N√©cessaire pour penalty='l1'\n",
        "            max_iter=self.max_iter,\n",
        "            random_state=42,\n",
        "            verbose=1\n",
        "        )\n",
        "        \n",
        "        self.models['L1-SVM'].fit(X_train, y_train)\n",
        "        print(\"‚úÖ L1-SVM entra√Æn√© avec succ√®s!\")\n",
        "        \n",
        "        # Nombre de features s√©lectionn√©es (sparsit√© du L1)\n",
        "        n_features_selected = np.sum(np.abs(self.models['L1-SVM'].coef_) > 1e-5)\n",
        "        print(f\"üìä Features s√©lectionn√©es (sparsit√© L1): {n_features_selected}/{X_train.shape[1]}\")\n",
        "    \n",
        "    def train_l2_svm(self, X_train, y_train):\n",
        "        \"\"\"\n",
        "        Entra√Æne le L2-SVM.\n",
        "        \n",
        "        √âquation (20):\n",
        "        min (1/p)||w||_2^2 + C * sum(max(0, 1 - y_i'(wx_i + b))^2)\n",
        "        \"\"\"\n",
        "        print(\"\\nüîÑ Entra√Ænement du L2-SVM...\")\n",
        "        print(f\"  Param√®tres: C={self.C}, penalty='l2', loss='squared_hinge'\")\n",
        "        \n",
        "        # L2-SVM (plus standard et diff√©rentiable)\n",
        "        self.models['L2-SVM'] = LinearSVC(\n",
        "            C=self.C,\n",
        "            penalty='l2',\n",
        "            loss='squared_hinge',\n",
        "            dual=True,\n",
        "            max_iter=self.max_iter,\n",
        "            random_state=42,\n",
        "            verbose=1\n",
        "        )\n",
        "        \n",
        "        self.models['L2-SVM'].fit(X_train, y_train)\n",
        "        print(\"‚úÖ L2-SVM entra√Æn√© avec succ√®s!\")\n",
        "    \n",
        "    def evaluate(self, X_test, y_test, model_name):\n",
        "        \"\"\"\n",
        "        √âvalue un mod√®le SVM.\n",
        "        \"\"\"\n",
        "        model = self.models[model_name]\n",
        "        y_pred = model.predict(X_test)\n",
        "        \n",
        "        # M√©triques\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "        \n",
        "        tn, fp, fn, tp = conf_matrix.ravel()\n",
        "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "        fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
        "        \n",
        "        self.results[model_name] = {\n",
        "            'accuracy': accuracy,\n",
        "            'confusion_matrix': conf_matrix,\n",
        "            'tpr': tpr,\n",
        "            'tnr': tnr,\n",
        "            'fpr': fpr,\n",
        "            'fnr': fnr,\n",
        "            'predictions': y_pred\n",
        "        }\n",
        "        \n",
        "        return self.results[model_name]\n",
        "    \n",
        "    def print_results(self, model_name):\n",
        "        \"\"\"Affiche les r√©sultats d'un mod√®le.\"\"\"\n",
        "        results = self.results[model_name]\n",
        "        \n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"R√âSULTATS: {model_name}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"\\n‚úÖ Accuracy: {results['accuracy']*100:.2f}%\")\n",
        "        print(f\"\\nüìä M√©triques d√©taill√©es:\")\n",
        "        print(f\"  TPR (Sensibilit√©):     {results['tpr']*100:.2f}%\")\n",
        "        print(f\"  TNR (Sp√©cificit√©):     {results['tnr']*100:.2f}%\")\n",
        "        print(f\"  FPR (Faux Positifs):   {results['fpr']*100:.2f}%\")\n",
        "        print(f\"  FNR (Faux N√©gatifs):   {results['fnr']*100:.2f}%\")\n",
        "        print(f\"{'='*60}\")\n",
        "    \n",
        "    def get_hyperplane_equation(self, model_name):\n",
        "        \"\"\"Retourne l'√©quation de l'hyperplan optimal.\"\"\"\n",
        "        model = self.models[model_name]\n",
        "        w = model.coef_[0]\n",
        "        b = model.intercept_[0]\n",
        "        \n",
        "        print(f\"\\nüìê √âquation de l'hyperplan {model_name}:\")\n",
        "        print(f\"  f(w,x) = w ¬∑ x + b = 0\")\n",
        "        print(f\"  Dimensions de w: {w.shape}\")\n",
        "        print(f\"  Biais b: {b:.4f}\")\n",
        "        print(f\"  Norme ||w||: {np.linalg.norm(w):.4f}\")\n",
        "        \n",
        "        return w, b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training_header"
      },
      "source": [
        "## 7. Entra√Ænement des Mod√®les"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_instance"
      },
      "outputs": [],
      "source": [
        "# Cr√©er l'instance\n",
        "svm_models = SVMModels(C=HYPERPARAMETERS['svm_c'], max_iter=HYPERPARAMETERS['max_iter'])\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ENTRA√éNEMENT DES MOD√àLES SVM\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_l1"
      },
      "outputs": [],
      "source": [
        "# Entra√Æner L1-SVM\n",
        "svm_models.train_l1_svm(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_l2"
      },
      "outputs": [],
      "source": [
        "# Entra√Æner L2-SVM\n",
        "svm_models.train_l2_svm(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eval_header"
      },
      "source": [
        "## 8. √âvaluation des Mod√®les"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eval_l1"
      },
      "outputs": [],
      "source": [
        "# √âvaluer L1-SVM\n",
        "results_l1 = svm_models.evaluate(X_test, y_test, 'L1-SVM')\n",
        "svm_models.print_results('L1-SVM')\n",
        "w_l1, b_l1 = svm_models.get_hyperplane_equation('L1-SVM')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eval_l2"
      },
      "outputs": [],
      "source": [
        "# √âvaluer L2-SVM\n",
        "results_l2 = svm_models.evaluate(X_test, y_test, 'L2-SVM')\n",
        "svm_models.print_results('L2-SVM')\n",
        "w_l2, b_l2 = svm_models.get_hyperplane_equation('L2-SVM')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viz_header"
      },
      "source": [
        "## 9. Visualisations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viz_confusion"
      },
      "outputs": [],
      "source": [
        "# Matrices de confusion\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "fig.suptitle('Matrices de Confusion - Mod√®les SVM', fontsize=16, fontweight='bold')\n",
        "\n",
        "# L1-SVM\n",
        "sns.heatmap(results_l1['confusion_matrix'], annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['B√©nin (-1)', 'Malin (+1)'],\n",
        "            yticklabels=['B√©nin (-1)', 'Malin (+1)'],\n",
        "            ax=axes[0], annot_kws={\"size\": 14})\n",
        "axes[0].set_xlabel('Classe Pr√©dite', fontsize=12, fontweight='bold')\n",
        "axes[0].set_ylabel('Classe R√©elle', fontsize=12, fontweight='bold')\n",
        "axes[0].set_title(f'L1-SVM\\nAccuracy: {results_l1[\"accuracy\"]*100:.2f}%', fontsize=14)\n",
        "\n",
        "# L2-SVM\n",
        "sns.heatmap(results_l2['confusion_matrix'], annot=True, fmt='d', cmap='Oranges',\n",
        "            xticklabels=['B√©nin (-1)', 'Malin (+1)'],\n",
        "            yticklabels=['B√©nin (-1)', 'Malin (+1)'],\n",
        "            ax=axes[1], annot_kws={\"size\": 14})\n",
        "axes[1].set_xlabel('Classe Pr√©dite', fontsize=12, fontweight='bold')\n",
        "axes[1].set_ylabel('Classe R√©elle', fontsize=12, fontweight='bold')\n",
        "axes[1].set_title(f'L2-SVM\\nAccuracy: {results_l2[\"accuracy\"]*100:.2f}%', fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viz_comparison"
      },
      "outputs": [],
      "source": [
        "# Comparaison des m√©triques\n",
        "metrics = ['Accuracy', 'TPR', 'TNR', 'FPR', 'FNR']\n",
        "l1_values = [results_l1['accuracy']*100, results_l1['tpr']*100, \n",
        "             results_l1['tnr']*100, results_l1['fpr']*100, results_l1['fnr']*100]\n",
        "l2_values = [results_l2['accuracy']*100, results_l2['tpr']*100, \n",
        "             results_l2['tnr']*100, results_l2['fpr']*100, results_l2['fnr']*100]\n",
        "\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 7))\n",
        "bars1 = ax.bar(x - width/2, l1_values, width, label='L1-SVM', color='#2E86AB')\n",
        "bars2 = ax.bar(x + width/2, l2_values, width, label='L2-SVM', color='#F18F01')\n",
        "\n",
        "ax.set_ylabel('Pourcentage (%)', fontsize=14, fontweight='bold')\n",
        "ax.set_title('Comparaison des Performances: L1-SVM vs L2-SVM', fontsize=16, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics, fontsize=12)\n",
        "ax.legend(fontsize=12)\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Ajouter les valeurs\n",
        "for bars in [bars1, bars2]:\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.annotate(f'{height:.1f}%',\n",
        "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                    xytext=(0, 3),\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "comparison_header"
      },
      "source": [
        "## 10. Comparaison avec le Tableau 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "comparison_table"
      },
      "outputs": [],
      "source": [
        "# R√©sultats attendus du Tableau 2\n",
        "comparison_data = {\n",
        "    'Model': ['SVM (Article)', 'L1-SVM (Notre)', 'L2-SVM (Notre)'],\n",
        "    'Accuracy': [96.09, results_l1['accuracy']*100, results_l2['accuracy']*100],\n",
        "    'TPR': [97.53, results_l1['tpr']*100, results_l2['tpr']*100],\n",
        "    'TNR': [93.62, results_l1['tnr']*100, results_l2['tnr']*100],\n",
        "    'FPR': [6.38, results_l1['fpr']*100, results_l2['fpr']*100],\n",
        "    'FNR': [2.47, results_l1['fnr']*100, results_l2['fnr']*100]\n",
        "}\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"COMPARAISON AVEC LE TABLEAU 2\")\n",
        "print(\"=\"*70)\n",
        "print(comparison_df.to_string(index=False))\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "optimization_header"
      },
      "source": [
        "## 11. Optimisation des Hyperparam√®tres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grid_search"
      },
      "outputs": [],
      "source": [
        "# Grid Search pour trouver le meilleur C\n",
        "print(\"\\nüîç Recherche du meilleur param√®tre C...\")\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 0.5, 1, 2, 5, 10, 20, 50]\n",
        "}\n",
        "\n",
        "# Pour L2-SVM\n",
        "grid_search_l2 = GridSearchCV(\n",
        "    LinearSVC(penalty='l2', loss='squared_hinge', dual=True, max_iter=5000, random_state=42),\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_search_l2.fit(X_train, y_train)\n",
        "\n",
        "print(f\"\\n‚úÖ Meilleur C pour L2-SVM: {grid_search_l2.best_params_['C']}\")\n",
        "print(f\"‚úÖ Meilleure accuracy (CV): {grid_search_l2.best_score_*100:.2f}%\")\n",
        "\n",
        "# R√©sultats de tous les C test√©s\n",
        "results_grid = pd.DataFrame(grid_search_l2.cv_results_)\n",
        "print(\"\\nüìä R√©sultats pour diff√©rentes valeurs de C:\")\n",
        "print(results_grid[['param_C', 'mean_test_score', 'std_test_score']].sort_values('mean_test_score', ascending=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viz_grid_search"
      },
      "outputs": [],
      "source": [
        "# Visualisation de l'impact de C\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(results_grid['param_C'], results_grid['mean_test_score']*100, \n",
        "         marker='o', linewidth=2, markersize=8, color='#2E86AB')\n",
        "plt.fill_between(results_grid['param_C'], \n",
        "                 (results_grid['mean_test_score'] - results_grid['std_test_score'])*100,\n",
        "                 (results_grid['mean_test_score'] + results_grid['std_test_score'])*100,\n",
        "                 alpha=0.3, color='#2E86AB')\n",
        "plt.xlabel('Param√®tre C', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Accuracy (%)', fontsize=14, fontweight='bold')\n",
        "plt.title('Impact du Param√®tre C sur la Performance du L2-SVM', fontsize=16, fontweight='bold')\n",
        "plt.xscale('log')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "save_header"
      },
      "source": [
        "## 12. Sauvegarde des Mod√®les"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save_models"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "print(\"\\nüíæ Sauvegarde des mod√®les...\")\n",
        "\n",
        "# Sauvegarder les mod√®les\n",
        "with open('l1_svm_model.pkl', 'wb') as f:\n",
        "    pickle.dump(svm_models.models['L1-SVM'], f)\n",
        "print(\"‚úì L1-SVM sauvegard√©: l1_svm_model.pkl\")\n",
        "\n",
        "with open('l2_svm_model.pkl', 'wb') as f:\n",
        "    pickle.dump(svm_models.models['L2-SVM'], f)\n",
        "print(\"‚úì L2-SVM sauvegard√©: l2_svm_model.pkl\")\n",
        "\n",
        "# Sauvegarder le scaler\n",
        "with open('svm_scaler.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "print(\"‚úì Scaler sauvegard√©: svm_scaler.pkl\")\n",
        "\n",
        "# Sauvegarder les hyperparam√®tres\n",
        "with open('svm_hyperparams.pkl', 'wb') as f:\n",
        "    pickle.dump(HYPERPARAMETERS, f)\n",
        "print(\"‚úì Hyperparam√®tres sauvegard√©s: svm_hyperparams.pkl\")\n",
        "\n",
        "print(\"\\n‚úÖ Tous les mod√®les ont √©t√© sauvegard√©s!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_models"
      },
      "outputs": [],
      "source": [
        "# T√©l√©charger les fichiers\n",
        "from google.colab import files\n",
        "\n",
        "print(\"üì• T√©l√©chargement des fichiers...\")\n",
        "files.download('l1_svm_model.pkl')\n",
        "files.download('l2_svm_model.pkl')\n",
        "files.download('svm_scaler.pkl')\n",
        "files.download('svm_hyperparams.pkl')\n",
        "print(\"‚úÖ T√©l√©chargement termin√©!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion_header"
      },
      "source": [
        "## 13. R√©sum√© et Conclusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "summary"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üìä R√âSUM√â DES MOD√àLES SVM\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nüéØ Mod√®les Impl√©ment√©s:\")\n",
        "print(\"  1. L1-SVM (Forme Primale - √âquation 19)\")\n",
        "print(\"     - Norme: L1 (Manhattan)\")\n",
        "print(\"     - Loss: Hinge Standard\")\n",
        "print(\"     - Sparsit√©: Oui (s√©lection de features)\")\n",
        "print(f\"     - Accuracy: {results_l1['accuracy']*100:.2f}%\")\n",
        "\n",
        "print(\"\\n  2. L2-SVM (√âquation 20)\")\n",
        "print(\"     - Norme: L2 (Euclidienne)\")\n",
        "print(\"     - Loss: Squared Hinge\")\n",
        "print(\"     - Diff√©rentiable: Oui\")\n",
        "print(f\"     - Accuracy: {results_l2['accuracy']*100:.2f}%\")\n",
        "\n",
        "print(\"\\nüìà Comparaison:\")\n",
        "print(f\"  Meilleur mod√®le: {'L1-SVM' if results_l1['accuracy'] > results_l2['accuracy'] else 'L2-SVM'}\")\n",
        "print(f\"  Diff√©rence d'accuracy: {abs(results_l1['accuracy'] - results_l2['accuracy'])*100:.2f}%\")\n",
        "\n",
        "print(\"\\nüîë Points Cl√©s:\")\n",
        "print(\"  ‚úì L1-SVM: Meilleur pour la s√©lection de features (sparsit√©)\")\n",
        "print(\"  ‚úì L2-SVM: Plus stable, diff√©rentiable, g√©n√©ralement plus performant\")\n",
        "print(\"  ‚úì Hyperplan optimal: f(w,x) = w¬∑x + b = 0\")\n",
        "print(f\"  ‚úì Param√®tre C optimal: {grid_search_l2.best_params_['C']}\")\n",
        "\n",
        "print(\"\\nüíæ Fichiers Sauvegard√©s:\")\n",
        "print(\"  ‚úì l1_svm_model.pkl\")\n",
        "print(\"  ‚úì l2_svm_model.pkl\")\n",
        "print(\"  ‚úì svm_scaler.pkl\")\n",
        "print(\"  ‚úì svm_hyperparams.pkl\")\n",
        "\n",
        "print(\"\\n‚úÖ Mod√®les pr√™ts pour la production!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "notes"
      },
      "source": [
        "## üìö Notes Techniques\n",
        "\n",
        "### Diff√©rences entre L1-SVM et L2-SVM:\n",
        "\n",
        "| Caract√©ristique | L1-SVM | L2-SVM |\n",
        "|----------------|---------|--------|\n",
        "| **Norme** | Manhattan ($||w||_1$) | Euclidienne ($||w||_2^2$) |\n",
        "| **Loss Function** | Hinge: $\\max(0, 1-y'(wx+b))$ | Squared Hinge: $\\max(0, 1-y'(wx+b))^2$ |\n",
        "| **Diff√©rentiabilit√©** | Non (√©quation 19) | Oui (√©quation 20) |\n",
        "| **Sparsit√©** | Oui (certains $w_i = 0$) | Non |\n",
        "| **S√©lection features** | Automatique | Non |\n",
        "| **Stabilit√©** | Moyenne | √âlev√©e |\n",
        "| **Usage** | Haute dimension, features redondantes | G√©n√©ral, plus robuste |\n",
        "\n",
        "### √âquations Impl√©ment√©es:\n",
        "\n",
        "**L1-SVM (√âquation 19):**\n",
        "$$\\min_{w,b} \\frac{1}{p}w^T w + C \\sum_{i=1}^{p} \\max(0, 1 - y_i'(w \\cdot x_i + b))$$\n",
        "\n",
        "**L2-SVM (√âquation 20):**\n",
        "$$\\min_{w,b} \\frac{1}{p}||w||_2^2 + C \\sum_{i=1}^{p} \\max(0, 1 - y_i'(w \\cdot x_i + b))^2$$\n",
        "\n",
        "### Hyperplan Optimal:\n",
        "L'hyperplan s√©parant les deux classes est d√©fini par:\n",
        "$$f(w,x) = w \\cdot x + b = 0$$\n",
        "\n",
        "Les pr√©dictions sont obtenues par:\n",
        "$$y' = \\text{sign}(w \\cdot x + b)$$\n",
        "\n",
        "---\n",
        "\n",
        "**Cr√©√© par**: maramchebbi  \n",
        "**Date**: 2025-11-19  \n",
        "**R√©f√©rence**: Section 2.4.6 Support Vector Machine"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
