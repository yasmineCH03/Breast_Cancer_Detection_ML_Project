{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b24d8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf157900",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "612019ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DATASET INFORMATION\n",
      "======================================================================\n",
      "Total samples: 569\n",
      "Number of features: 30\n",
      "Malignant cases (0): 212\n",
      "Benign cases (1): 357\n",
      "\n",
      "Feature names: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness']... (showing first 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATASET INFORMATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total samples: {X.shape[0]}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(f\"Malignant cases (0): {np.sum(y == 0)}\")\n",
    "print(f\"Benign cases (1): {np.sum(y == 1)}\")\n",
    "print(f\"\\nFeature names: {data.feature_names[:5]}... (showing first 5)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "517740eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X, columns=data.feature_names)\n",
    "df['target'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ad0c7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows of the dataset:\n",
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "2           0.15990          0.1974              0.12790         0.2069   \n",
      "3           0.28390          0.2414              0.10520         0.2597   \n",
      "4           0.13280          0.1980              0.10430         0.1809   \n",
      "\n",
      "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
      "0                 0.07871  ...          17.33           184.60      2019.0   \n",
      "1                 0.05667  ...          23.41           158.80      1956.0   \n",
      "2                 0.05999  ...          25.53           152.50      1709.0   \n",
      "3                 0.09744  ...          26.50            98.87       567.7   \n",
      "4                 0.05883  ...          16.67           152.20      1575.0   \n",
      "\n",
      "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
      "0            0.1622             0.6656           0.7119                0.2654   \n",
      "1            0.1238             0.1866           0.2416                0.1860   \n",
      "2            0.1444             0.4245           0.4504                0.2430   \n",
      "3            0.2098             0.8663           0.6869                0.2575   \n",
      "4            0.1374             0.2050           0.4000                0.1625   \n",
      "\n",
      "   worst symmetry  worst fractal dimension  target  \n",
      "0          0.4601                  0.11890       0  \n",
      "1          0.2750                  0.08902       0  \n",
      "2          0.3613                  0.08758       0  \n",
      "3          0.6638                  0.17300       0  \n",
      "4          0.2364                  0.07678       0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "Dataset statistics:\n",
      "       mean radius  mean texture  mean perimeter    mean area  \\\n",
      "count   569.000000    569.000000      569.000000   569.000000   \n",
      "mean     14.127292     19.289649       91.969033   654.889104   \n",
      "std       3.524049      4.301036       24.298981   351.914129   \n",
      "min       6.981000      9.710000       43.790000   143.500000   \n",
      "25%      11.700000     16.170000       75.170000   420.300000   \n",
      "50%      13.370000     18.840000       86.240000   551.100000   \n",
      "75%      15.780000     21.800000      104.100000   782.700000   \n",
      "max      28.110000     39.280000      188.500000  2501.000000   \n",
      "\n",
      "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
      "count       569.000000        569.000000      569.000000           569.000000   \n",
      "mean          0.096360          0.104341        0.088799             0.048919   \n",
      "std           0.014064          0.052813        0.079720             0.038803   \n",
      "min           0.052630          0.019380        0.000000             0.000000   \n",
      "25%           0.086370          0.064920        0.029560             0.020310   \n",
      "50%           0.095870          0.092630        0.061540             0.033500   \n",
      "75%           0.105300          0.130400        0.130700             0.074000   \n",
      "max           0.163400          0.345400        0.426800             0.201200   \n",
      "\n",
      "       mean symmetry  mean fractal dimension  ...  worst texture  \\\n",
      "count     569.000000              569.000000  ...     569.000000   \n",
      "mean        0.181162                0.062798  ...      25.677223   \n",
      "std         0.027414                0.007060  ...       6.146258   \n",
      "min         0.106000                0.049960  ...      12.020000   \n",
      "25%         0.161900                0.057700  ...      21.080000   \n",
      "50%         0.179200                0.061540  ...      25.410000   \n",
      "75%         0.195700                0.066120  ...      29.720000   \n",
      "max         0.304000                0.097440  ...      49.540000   \n",
      "\n",
      "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
      "count       569.000000   569.000000        569.000000         569.000000   \n",
      "mean        107.261213   880.583128          0.132369           0.254265   \n",
      "std          33.602542   569.356993          0.022832           0.157336   \n",
      "min          50.410000   185.200000          0.071170           0.027290   \n",
      "25%          84.110000   515.300000          0.116600           0.147200   \n",
      "50%          97.660000   686.500000          0.131300           0.211900   \n",
      "75%         125.400000  1084.000000          0.146000           0.339100   \n",
      "max         251.200000  4254.000000          0.222600           1.058000   \n",
      "\n",
      "       worst concavity  worst concave points  worst symmetry  \\\n",
      "count       569.000000            569.000000      569.000000   \n",
      "mean          0.272188              0.114606        0.290076   \n",
      "std           0.208624              0.065732        0.061867   \n",
      "min           0.000000              0.000000        0.156500   \n",
      "25%           0.114500              0.064930        0.250400   \n",
      "50%           0.226700              0.099930        0.282200   \n",
      "75%           0.382900              0.161400        0.317900   \n",
      "max           1.252000              0.291000        0.663800   \n",
      "\n",
      "       worst fractal dimension      target  \n",
      "count               569.000000  569.000000  \n",
      "mean                  0.083946    0.627417  \n",
      "std                   0.018061    0.483918  \n",
      "min                   0.055040    0.000000  \n",
      "25%                   0.071460    0.000000  \n",
      "50%                   0.080040    1.000000  \n",
      "75%                   0.092080    1.000000  \n",
      "max                   0.207500    1.000000  \n",
      "\n",
      "[8 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nDataset statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0889fcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 398 samples\n",
      "Testing set size: 171 samples\n"
     ]
    }
   ],
   "source": [
    "# Split data: 70% training, 30% testing (as per the paper)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Apply Standardization: X' = (X - Î¼) / Ïƒ\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "393b5657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standardization applied!\n",
      "Training data mean (after scaling): [-4.97480337e-15  2.74863884e-15  2.03912822e-15]\n",
      "Training data std (after scaling): [1. 1. 1.]\n",
      "(Showing first 3 features - all should be ~0 mean and ~1 std)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStandardization applied!\")\n",
    "print(f\"Training data mean (after scaling): {np.mean(X_train_scaled, axis=0)[:3]}\")\n",
    "print(f\"Training data std (after scaling): {np.std(X_train_scaled, axis=0)[:3]}\")\n",
    "print(\"(Showing first 3 features - all should be ~0 mean and ~1 std)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98edcbaf",
   "metadata": {},
   "source": [
    "ModÃ¨le MLP Reproduit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e22d21da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MLP REPRODUCTION - PAPER ARCHITECTURE\n",
      "======================================================================\n",
      "MLP Paper Architecture Summary:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">15,500</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">250,500</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">250,500</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            â”‚        \u001b[38;5;34m15,500\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            â”‚       \u001b[38;5;34m250,500\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            â”‚       \u001b[38;5;34m250,500\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m501\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">517,001</span> (1.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m517,001\u001b[0m (1.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">517,001</span> (1.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m517,001\u001b[0m (1.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyperparameters from paper:\n",
      "- Architecture: [500, 500, 500]\n",
      "- Learning rate: 0.01\n",
      "- Batch size: 128\n",
      "- Epochs: 3000\n",
      "- Dropout: None\n",
      "\n",
      "Training reproduction MLP...\n",
      "Epoch 1/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.5692 - loss: 1.3773 - val_accuracy: 0.9375 - val_loss: 0.5789\n",
      "Epoch 2/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9434 - loss: 0.3405 - val_accuracy: 0.9875 - val_loss: 0.1227\n",
      "Epoch 3/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9497 - loss: 0.2695 - val_accuracy: 0.9875 - val_loss: 0.0455\n",
      "Epoch 4/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9843 - loss: 0.1245 - val_accuracy: 1.0000 - val_loss: 0.0090\n",
      "Epoch 5/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9780 - loss: 0.0826 - val_accuracy: 1.0000 - val_loss: 0.0180\n",
      "Epoch 6/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9843 - loss: 0.0597 - val_accuracy: 1.0000 - val_loss: 0.0231\n",
      "Epoch 7/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9811 - loss: 0.0412 - val_accuracy: 0.9875 - val_loss: 0.0288\n",
      "Epoch 8/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9906 - loss: 0.0318 - val_accuracy: 0.9875 - val_loss: 0.0416\n",
      "Epoch 9/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9906 - loss: 0.0287 - val_accuracy: 0.9875 - val_loss: 0.0472\n",
      "Epoch 10/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9874 - loss: 0.0254 - val_accuracy: 0.9875 - val_loss: 0.0395\n",
      "Epoch 11/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9937 - loss: 0.0186 - val_accuracy: 0.9875 - val_loss: 0.0284\n",
      "Epoch 12/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9937 - loss: 0.0152 - val_accuracy: 1.0000 - val_loss: 0.0169\n",
      "Epoch 13/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9969 - loss: 0.0117 - val_accuracy: 1.0000 - val_loss: 0.0101\n",
      "Epoch 14/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9969 - loss: 0.0093 - val_accuracy: 1.0000 - val_loss: 0.0071\n",
      "Epoch 15/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9969 - loss: 0.0077 - val_accuracy: 1.0000 - val_loss: 0.0069\n",
      "Epoch 16/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9969 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 0.0086\n",
      "Epoch 17/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 0.0102\n",
      "Epoch 18/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 0.0098\n",
      "Epoch 19/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0082\n",
      "Epoch 20/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0072\n",
      "Epoch 21/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0077\n",
      "Epoch 22/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 9.3361e-04 - val_accuracy: 1.0000 - val_loss: 0.0090\n",
      "Epoch 23/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 6.9684e-04 - val_accuracy: 1.0000 - val_loss: 0.0103\n",
      "Epoch 24/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 5.2531e-04 - val_accuracy: 1.0000 - val_loss: 0.0115\n",
      "Epoch 25/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 4.0327e-04 - val_accuracy: 1.0000 - val_loss: 0.0122\n",
      "Epoch 26/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 3.1473e-04 - val_accuracy: 1.0000 - val_loss: 0.0126\n",
      "Epoch 27/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.5090e-04 - val_accuracy: 1.0000 - val_loss: 0.0130\n",
      "Epoch 28/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.0592e-04 - val_accuracy: 0.9875 - val_loss: 0.0138\n",
      "Epoch 29/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.7042e-04 - val_accuracy: 0.9875 - val_loss: 0.0149\n",
      "Epoch 30/150\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.4310e-04 - val_accuracy: 0.9875 - val_loss: 0.0153\n",
      "\n",
      "Evaluating MLP Reproduction...\n",
      "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\n",
      "ğŸ“Š MLP REPRODUCTION RESULTS:\n",
      "Accuracy: 0.9649 (96.49%)\n",
      "Precision: 0.9903\n",
      "Recall (Sensitivity): 0.9533\n",
      "F1-Score: 0.9714\n",
      "False Negative Rate: 0.0467\n",
      "Confusion Matrix:\n",
      "[[ 63   1]\n",
      " [  5 102]]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 1. MLP REPRODUCTION (Paper Architecture)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MLP REPRODUCTION - PAPER ARCHITECTURE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Reproduce the paper's MLP: [500, 500, 500]\n",
    "mlp_paper = Sequential([\n",
    "    Dense(500, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(500, activation='relu'),\n",
    "    Dense(500, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "mlp_paper.compile(\n",
    "    optimizer=Adam(learning_rate=1e-2),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"MLP Paper Architecture Summary:\")\n",
    "mlp_paper.summary()\n",
    "\n",
    "print(f\"\\nHyperparameters from paper:\")\n",
    "print(f\"- Architecture: [500, 500, 500]\")\n",
    "print(f\"- Learning rate: 0.01\")\n",
    "print(f\"- Batch size: 128\")\n",
    "print(f\"- Epochs: 3000\")\n",
    "print(f\"- Dropout: None\")\n",
    "\n",
    "# Train the reproduction model\n",
    "print(\"\\nTraining reproduction MLP...\")\n",
    "history_paper = mlp_paper.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    batch_size=128,\n",
    "    epochs=150,  # Reduced for demonstration, paper used 3000\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    "    callbacks=[EarlyStopping(patience=15, restore_best_weights=True, monitor='val_loss')]\n",
    ")\n",
    "\n",
    "# Evaluate reproduction model\n",
    "print(\"\\nEvaluating MLP Reproduction...\")\n",
    "y_pred_mlp_paper = (mlp_paper.predict(X_test_scaled) > 0.5).astype(\"int32\")\n",
    "acc_mlp_paper = accuracy_score(y_test, y_pred_mlp_paper)\n",
    "\n",
    "# Calculate additional metrics\n",
    "precision_mlp, recall_mlp, f1_mlp, _ = precision_recall_fscore_support(y_test, y_pred_mlp_paper, average='binary')\n",
    "cm_mlp = confusion_matrix(y_test, y_pred_mlp_paper)\n",
    "tn, fp, fn, tp = cm_mlp.ravel()\n",
    "\n",
    "print(f\"\\nğŸ“Š MLP REPRODUCTION RESULTS:\")\n",
    "print(f\"Accuracy: {acc_mlp_paper:.4f} ({acc_mlp_paper*100:.2f}%)\")\n",
    "print(f\"Precision: {precision_mlp:.4f}\")\n",
    "print(f\"Recall (Sensitivity): {recall_mlp:.4f}\")\n",
    "print(f\"F1-Score: {f1_mlp:.4f}\")\n",
    "print(f\"False Negative Rate: {fn/(fn+tp):.4f}\")\n",
    "print(f\"Confusion Matrix:\")\n",
    "print(cm_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc81e40c",
   "metadata": {},
   "source": [
    "ModÃ¨le MLP OptimisÃ©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb31b95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MLP OPTIMIZED MODEL\n",
      "======================================================================\n",
      "Optimized MLP Architecture Summary:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,936</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m7,936\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m1,024\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚        \u001b[38;5;34m65,792\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m1,024\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_10 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚        \u001b[38;5;34m32,896\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_11 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m129\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,313</span> (427.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,313\u001b[0m (427.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">108,033</span> (422.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m108,033\u001b[0m (422.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> (5.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,280\u001b[0m (5.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization Improvements:\n",
      "- Added L2 regularization (0.001)\n",
      "- Added Batch Normalization\n",
      "- Added Dropout (0.3, 0.3, 0.2)\n",
      "- Reduced learning rate (0.001)\n",
      "- Smaller batch size (32)\n",
      "- Early stopping and learning rate reduction\n",
      "\n",
      "Training optimized MLP...\n",
      "Epoch 1/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8019 - loss: 0.8773 - val_accuracy: 0.9750 - val_loss: 0.8206 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9340 - loss: 0.6505 - val_accuracy: 0.9875 - val_loss: 0.7365 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9591 - loss: 0.5817 - val_accuracy: 0.9875 - val_loss: 0.6962 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9654 - loss: 0.5835 - val_accuracy: 0.9875 - val_loss: 0.6668 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9874 - loss: 0.5376 - val_accuracy: 0.9875 - val_loss: 0.6373 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9843 - loss: 0.5362 - val_accuracy: 0.9750 - val_loss: 0.6153 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9843 - loss: 0.5223 - val_accuracy: 0.9750 - val_loss: 0.5998 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9874 - loss: 0.4945 - val_accuracy: 0.9750 - val_loss: 0.5823 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9937 - loss: 0.4810 - val_accuracy: 0.9750 - val_loss: 0.5615 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9906 - loss: 0.4809 - val_accuracy: 0.9625 - val_loss: 0.5498 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9874 - loss: 0.4758 - val_accuracy: 0.9750 - val_loss: 0.5418 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9906 - loss: 0.4656 - val_accuracy: 0.9750 - val_loss: 0.5202 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9874 - loss: 0.4687 - val_accuracy: 0.9750 - val_loss: 0.4981 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.4486 - val_accuracy: 0.9750 - val_loss: 0.4871 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9906 - loss: 0.4441 - val_accuracy: 0.9750 - val_loss: 0.4834 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.4320 - val_accuracy: 0.9750 - val_loss: 0.4742 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9937 - loss: 0.4348 - val_accuracy: 0.9750 - val_loss: 0.4694 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9937 - loss: 0.4293 - val_accuracy: 0.9750 - val_loss: 0.4535 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.4083 - val_accuracy: 0.9875 - val_loss: 0.4398 - learning_rate: 0.0010\n",
      "Epoch 20/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.4030 - val_accuracy: 0.9750 - val_loss: 0.4319 - learning_rate: 0.0010\n",
      "Epoch 21/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.3955 - val_accuracy: 0.9750 - val_loss: 0.4285 - learning_rate: 0.0010\n",
      "Epoch 22/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.3947 - val_accuracy: 0.9750 - val_loss: 0.4253 - learning_rate: 0.0010\n",
      "Epoch 23/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.3859 - val_accuracy: 0.9750 - val_loss: 0.4148 - learning_rate: 0.0010\n",
      "Epoch 24/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.3777 - val_accuracy: 0.9875 - val_loss: 0.4036 - learning_rate: 0.0010\n",
      "Epoch 25/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.3752 - val_accuracy: 0.9750 - val_loss: 0.4082 - learning_rate: 0.0010\n",
      "Epoch 26/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9937 - loss: 0.3757 - val_accuracy: 1.0000 - val_loss: 0.3739 - learning_rate: 0.0010\n",
      "Epoch 27/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.3602 - val_accuracy: 1.0000 - val_loss: 0.3646 - learning_rate: 0.0010\n",
      "Epoch 28/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.3587 - val_accuracy: 1.0000 - val_loss: 0.3652 - learning_rate: 0.0010\n",
      "Epoch 29/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9937 - loss: 0.3562 - val_accuracy: 0.9750 - val_loss: 0.3681 - learning_rate: 0.0010\n",
      "Epoch 30/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.3445 - val_accuracy: 0.9750 - val_loss: 0.3729 - learning_rate: 0.0010\n",
      "Epoch 31/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9906 - loss: 0.3497 - val_accuracy: 1.0000 - val_loss: 0.3438 - learning_rate: 0.0010\n",
      "Epoch 32/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.3328 - val_accuracy: 1.0000 - val_loss: 0.3356 - learning_rate: 0.0010\n",
      "Epoch 33/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.3307 - val_accuracy: 1.0000 - val_loss: 0.3294 - learning_rate: 0.0010\n",
      "Epoch 34/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.3267 - val_accuracy: 1.0000 - val_loss: 0.3252 - learning_rate: 0.0010\n",
      "Epoch 35/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.3159 - val_accuracy: 1.0000 - val_loss: 0.3247 - learning_rate: 0.0010\n",
      "Epoch 36/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.3112 - val_accuracy: 1.0000 - val_loss: 0.3133 - learning_rate: 0.0010\n",
      "Epoch 37/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.3043 - val_accuracy: 1.0000 - val_loss: 0.3078 - learning_rate: 0.0010\n",
      "Epoch 38/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9937 - loss: 0.3129 - val_accuracy: 1.0000 - val_loss: 0.3057 - learning_rate: 0.0010\n",
      "Epoch 39/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.3019 - val_accuracy: 1.0000 - val_loss: 0.2945 - learning_rate: 0.0010\n",
      "Epoch 40/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.2949 - val_accuracy: 1.0000 - val_loss: 0.2901 - learning_rate: 0.0010\n",
      "Epoch 41/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.2869 - val_accuracy: 1.0000 - val_loss: 0.2858 - learning_rate: 0.0010\n",
      "Epoch 42/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.2837 - val_accuracy: 1.0000 - val_loss: 0.2825 - learning_rate: 0.0010\n",
      "Epoch 43/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.2769 - val_accuracy: 1.0000 - val_loss: 0.2796 - learning_rate: 0.0010\n",
      "Epoch 44/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.2725 - val_accuracy: 1.0000 - val_loss: 0.2792 - learning_rate: 0.0010\n",
      "Epoch 45/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.2761 - val_accuracy: 1.0000 - val_loss: 0.2700 - learning_rate: 0.0010\n",
      "Epoch 46/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.2629 - val_accuracy: 1.0000 - val_loss: 0.2717 - learning_rate: 0.0010\n",
      "Epoch 47/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.2604 - val_accuracy: 1.0000 - val_loss: 0.2656 - learning_rate: 0.0010\n",
      "Epoch 48/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.2662 - val_accuracy: 0.9875 - val_loss: 0.2677 - learning_rate: 0.0010\n",
      "Epoch 49/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.2519 - val_accuracy: 1.0000 - val_loss: 0.2600 - learning_rate: 0.0010\n",
      "Epoch 50/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.2456 - val_accuracy: 1.0000 - val_loss: 0.2463 - learning_rate: 0.0010\n",
      "Epoch 51/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.2416 - val_accuracy: 1.0000 - val_loss: 0.2428 - learning_rate: 0.0010\n",
      "Epoch 52/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.2389 - val_accuracy: 0.9875 - val_loss: 0.2489 - learning_rate: 0.0010\n",
      "Epoch 53/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.2336 - val_accuracy: 1.0000 - val_loss: 0.2362 - learning_rate: 0.0010\n",
      "Epoch 54/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.2332 - val_accuracy: 1.0000 - val_loss: 0.2311 - learning_rate: 0.0010\n",
      "Epoch 55/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.2235 - val_accuracy: 0.9875 - val_loss: 0.2376 - learning_rate: 0.0010\n",
      "Epoch 56/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9937 - loss: 0.2410 - val_accuracy: 0.9875 - val_loss: 0.2537 - learning_rate: 0.0010\n",
      "Epoch 57/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.2258 - val_accuracy: 1.0000 - val_loss: 0.2326 - learning_rate: 0.0010\n",
      "Epoch 58/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.2148 - val_accuracy: 1.0000 - val_loss: 0.2248 - learning_rate: 0.0010\n",
      "Epoch 59/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.2151 - val_accuracy: 1.0000 - val_loss: 0.2242 - learning_rate: 0.0010\n",
      "Epoch 60/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.2093 - val_accuracy: 0.9875 - val_loss: 0.2244 - learning_rate: 0.0010\n",
      "Epoch 61/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9937 - loss: 0.2104 - val_accuracy: 0.9875 - val_loss: 0.2199 - learning_rate: 0.0010\n",
      "Epoch 62/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9906 - loss: 0.2218 - val_accuracy: 0.9750 - val_loss: 0.2337 - learning_rate: 0.0010\n",
      "Epoch 63/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9906 - loss: 0.2242 - val_accuracy: 0.9750 - val_loss: 0.2287 - learning_rate: 0.0010\n",
      "Epoch 64/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9874 - loss: 0.2218 - val_accuracy: 0.9750 - val_loss: 0.2466 - learning_rate: 0.0010\n",
      "Epoch 65/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.2082 - val_accuracy: 1.0000 - val_loss: 0.2112 - learning_rate: 0.0010\n",
      "Epoch 66/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9937 - loss: 0.2072 - val_accuracy: 0.9875 - val_loss: 0.2085 - learning_rate: 0.0010\n",
      "Epoch 67/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.1918 - val_accuracy: 0.9875 - val_loss: 0.2153 - learning_rate: 0.0010\n",
      "Epoch 68/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9906 - loss: 0.2027 - val_accuracy: 0.9875 - val_loss: 0.2040 - learning_rate: 0.0010\n",
      "Epoch 69/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1889 - val_accuracy: 0.9875 - val_loss: 0.2088 - learning_rate: 0.0010\n",
      "Epoch 70/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9937 - loss: 0.1930 - val_accuracy: 0.9875 - val_loss: 0.1979 - learning_rate: 0.0010\n",
      "Epoch 71/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.1832 - val_accuracy: 0.9875 - val_loss: 0.1924 - learning_rate: 0.0010\n",
      "Epoch 72/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.1904 - val_accuracy: 0.9875 - val_loss: 0.1966 - learning_rate: 0.0010\n",
      "Epoch 73/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.1792 - val_accuracy: 1.0000 - val_loss: 0.1818 - learning_rate: 0.0010\n",
      "Epoch 74/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.1722 - val_accuracy: 1.0000 - val_loss: 0.1763 - learning_rate: 0.0010\n",
      "Epoch 75/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1692 - val_accuracy: 1.0000 - val_loss: 0.1721 - learning_rate: 0.0010\n",
      "Epoch 76/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.1668 - val_accuracy: 0.9875 - val_loss: 0.1921 - learning_rate: 0.0010\n",
      "Epoch 77/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.1636 - val_accuracy: 0.9875 - val_loss: 0.2030 - learning_rate: 0.0010\n",
      "Epoch 78/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1615 - val_accuracy: 0.9875 - val_loss: 0.1905 - learning_rate: 0.0010\n",
      "Epoch 79/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1581 - val_accuracy: 0.9875 - val_loss: 0.1844 - learning_rate: 0.0010\n",
      "Epoch 80/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1546 - val_accuracy: 0.9875 - val_loss: 0.1750 - learning_rate: 0.0010\n",
      "Epoch 81/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1508 - val_accuracy: 0.9875 - val_loss: 0.1725 - learning_rate: 0.0010\n",
      "Epoch 82/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1483 - val_accuracy: 0.9875 - val_loss: 0.1663 - learning_rate: 0.0010\n",
      "Epoch 83/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1458 - val_accuracy: 0.9875 - val_loss: 0.1594 - learning_rate: 0.0010\n",
      "Epoch 84/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1444 - val_accuracy: 0.9875 - val_loss: 0.1626 - learning_rate: 0.0010\n",
      "Epoch 85/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1449 - val_accuracy: 0.9875 - val_loss: 0.1565 - learning_rate: 0.0010\n",
      "Epoch 86/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.1384 - val_accuracy: 1.0000 - val_loss: 0.1471 - learning_rate: 0.0010\n",
      "Epoch 87/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1382 - val_accuracy: 0.9875 - val_loss: 0.1475 - learning_rate: 0.0010\n",
      "Epoch 88/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1361 - val_accuracy: 1.0000 - val_loss: 0.1499 - learning_rate: 0.0010\n",
      "Epoch 89/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.1344 - val_accuracy: 1.0000 - val_loss: 0.1375 - learning_rate: 0.0010\n",
      "Epoch 90/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1309 - val_accuracy: 1.0000 - val_loss: 0.1390 - learning_rate: 0.0010\n",
      "Epoch 91/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.1322 - val_accuracy: 0.9875 - val_loss: 0.1444 - learning_rate: 0.0010\n",
      "Epoch 92/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1270 - val_accuracy: 0.9875 - val_loss: 0.1519 - learning_rate: 0.0010\n",
      "Epoch 93/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1245 - val_accuracy: 0.9750 - val_loss: 0.1570 - learning_rate: 0.0010\n",
      "Epoch 94/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.1237 - val_accuracy: 0.9875 - val_loss: 0.1387 - learning_rate: 0.0010\n",
      "Epoch 95/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.1200 - val_accuracy: 0.9875 - val_loss: 0.1369 - learning_rate: 0.0010\n",
      "Epoch 96/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.1239 - val_accuracy: 0.9875 - val_loss: 0.1558 - learning_rate: 0.0010\n",
      "Epoch 97/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.1205 - val_accuracy: 0.9875 - val_loss: 0.1318 - learning_rate: 0.0010\n",
      "Epoch 98/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1150 - val_accuracy: 1.0000 - val_loss: 0.1166 - learning_rate: 0.0010\n",
      "Epoch 99/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9906 - loss: 0.1235 - val_accuracy: 1.0000 - val_loss: 0.1219 - learning_rate: 0.0010\n",
      "Epoch 100/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1153 - val_accuracy: 1.0000 - val_loss: 0.1194 - learning_rate: 0.0010\n",
      "Epoch 101/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.1133 - val_accuracy: 1.0000 - val_loss: 0.1172 - learning_rate: 0.0010\n",
      "Epoch 102/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.1149 - val_accuracy: 0.9875 - val_loss: 0.1407 - learning_rate: 0.0010\n",
      "Epoch 103/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.1235 - val_accuracy: 0.9750 - val_loss: 0.1537 - learning_rate: 0.0010\n",
      "Epoch 104/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.1231 - val_accuracy: 0.9875 - val_loss: 0.1404 - learning_rate: 0.0010\n",
      "Epoch 105/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.1115 - val_accuracy: 0.9750 - val_loss: 0.1915 - learning_rate: 0.0010\n",
      "Epoch 106/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.1124 - val_accuracy: 0.9750 - val_loss: 0.1889 - learning_rate: 0.0010\n",
      "Epoch 107/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.1098 - val_accuracy: 0.9750 - val_loss: 0.1266 - learning_rate: 0.0010\n",
      "Epoch 108/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9937 - loss: 0.1208 - val_accuracy: 0.9750 - val_loss: 0.1958 - learning_rate: 0.0010\n",
      "Epoch 109/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.1337 - val_accuracy: 0.9500 - val_loss: 0.1930 - learning_rate: 5.0000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9906 - loss: 0.1141 - val_accuracy: 0.9875 - val_loss: 0.1310 - learning_rate: 5.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1035 - val_accuracy: 0.9875 - val_loss: 0.1345 - learning_rate: 5.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.1099 - val_accuracy: 0.9875 - val_loss: 0.1231 - learning_rate: 5.0000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9906 - loss: 0.1213 - val_accuracy: 1.0000 - val_loss: 0.1108 - learning_rate: 5.0000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.1025 - val_accuracy: 0.9875 - val_loss: 0.1256 - learning_rate: 5.0000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1034 - val_accuracy: 0.9875 - val_loss: 0.1437 - learning_rate: 5.0000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.1042 - val_accuracy: 0.9875 - val_loss: 0.1478 - learning_rate: 5.0000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0992 - val_accuracy: 0.9875 - val_loss: 0.1437 - learning_rate: 5.0000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.1042 - val_accuracy: 1.0000 - val_loss: 0.1083 - learning_rate: 5.0000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.1006 - val_accuracy: 1.0000 - val_loss: 0.1012 - learning_rate: 5.0000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.1039 - val_accuracy: 1.0000 - val_loss: 0.1059 - learning_rate: 5.0000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.1038 - val_accuracy: 1.0000 - val_loss: 0.1033 - learning_rate: 5.0000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.1002 - val_accuracy: 1.0000 - val_loss: 0.1047 - learning_rate: 5.0000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.1090 - val_accuracy: 1.0000 - val_loss: 0.1079 - learning_rate: 5.0000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.1051 - val_accuracy: 1.0000 - val_loss: 0.1008 - learning_rate: 5.0000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0977 - val_accuracy: 0.9875 - val_loss: 0.1118 - learning_rate: 5.0000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0939 - val_accuracy: 0.9875 - val_loss: 0.1134 - learning_rate: 5.0000e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0946 - val_accuracy: 0.9875 - val_loss: 0.1130 - learning_rate: 5.0000e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0928 - val_accuracy: 0.9875 - val_loss: 0.1147 - learning_rate: 5.0000e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0923 - val_accuracy: 0.9875 - val_loss: 0.1072 - learning_rate: 5.0000e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0901 - val_accuracy: 1.0000 - val_loss: 0.1027 - learning_rate: 5.0000e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0894 - val_accuracy: 1.0000 - val_loss: 0.1026 - learning_rate: 5.0000e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0884 - val_accuracy: 1.0000 - val_loss: 0.1019 - learning_rate: 5.0000e-04\n",
      "Epoch 133/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0892 - val_accuracy: 0.9875 - val_loss: 0.1046 - learning_rate: 5.0000e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0865 - val_accuracy: 0.9875 - val_loss: 0.1049 - learning_rate: 5.0000e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0860 - val_accuracy: 0.9875 - val_loss: 0.1046 - learning_rate: 2.5000e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0856 - val_accuracy: 0.9875 - val_loss: 0.1037 - learning_rate: 2.5000e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0854 - val_accuracy: 0.9875 - val_loss: 0.1030 - learning_rate: 2.5000e-04\n",
      "Epoch 138/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0851 - val_accuracy: 0.9875 - val_loss: 0.1006 - learning_rate: 2.5000e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0843 - val_accuracy: 0.9875 - val_loss: 0.0988 - learning_rate: 2.5000e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0854 - val_accuracy: 0.9875 - val_loss: 0.0997 - learning_rate: 2.5000e-04\n",
      "Epoch 141/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0836 - val_accuracy: 0.9875 - val_loss: 0.0997 - learning_rate: 2.5000e-04\n",
      "Epoch 142/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0830 - val_accuracy: 0.9875 - val_loss: 0.0996 - learning_rate: 2.5000e-04\n",
      "Epoch 143/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0833 - val_accuracy: 0.9875 - val_loss: 0.1004 - learning_rate: 2.5000e-04\n",
      "Epoch 144/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0824 - val_accuracy: 0.9875 - val_loss: 0.1010 - learning_rate: 2.5000e-04\n",
      "Epoch 145/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0819 - val_accuracy: 0.9875 - val_loss: 0.1005 - learning_rate: 2.5000e-04\n",
      "Epoch 146/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0819 - val_accuracy: 0.9875 - val_loss: 0.1000 - learning_rate: 2.5000e-04\n",
      "Epoch 147/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0814 - val_accuracy: 0.9875 - val_loss: 0.0981 - learning_rate: 2.5000e-04\n",
      "Epoch 148/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0808 - val_accuracy: 0.9875 - val_loss: 0.0966 - learning_rate: 2.5000e-04\n",
      "Epoch 149/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0803 - val_accuracy: 0.9875 - val_loss: 0.0954 - learning_rate: 2.5000e-04\n",
      "Epoch 150/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0807 - val_accuracy: 0.9875 - val_loss: 0.0953 - learning_rate: 2.5000e-04\n",
      "Epoch 151/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0794 - val_accuracy: 0.9875 - val_loss: 0.0948 - learning_rate: 2.5000e-04\n",
      "Epoch 152/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0791 - val_accuracy: 0.9875 - val_loss: 0.0947 - learning_rate: 2.5000e-04\n",
      "Epoch 153/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0787 - val_accuracy: 0.9875 - val_loss: 0.0942 - learning_rate: 2.5000e-04\n",
      "Epoch 154/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0783 - val_accuracy: 0.9875 - val_loss: 0.0934 - learning_rate: 2.5000e-04\n",
      "Epoch 155/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0778 - val_accuracy: 0.9875 - val_loss: 0.0931 - learning_rate: 2.5000e-04\n",
      "Epoch 156/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0776 - val_accuracy: 0.9875 - val_loss: 0.0927 - learning_rate: 2.5000e-04\n",
      "Epoch 157/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0775 - val_accuracy: 0.9875 - val_loss: 0.0908 - learning_rate: 2.5000e-04\n",
      "Epoch 158/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0767 - val_accuracy: 1.0000 - val_loss: 0.0897 - learning_rate: 2.5000e-04\n",
      "Epoch 159/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0769 - val_accuracy: 0.9875 - val_loss: 0.0896 - learning_rate: 2.5000e-04\n",
      "Epoch 160/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0761 - val_accuracy: 0.9875 - val_loss: 0.0886 - learning_rate: 2.5000e-04\n",
      "Epoch 161/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0754 - val_accuracy: 0.9875 - val_loss: 0.0877 - learning_rate: 2.5000e-04\n",
      "Epoch 162/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0752 - val_accuracy: 0.9875 - val_loss: 0.0870 - learning_rate: 2.5000e-04\n",
      "Epoch 163/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0746 - val_accuracy: 1.0000 - val_loss: 0.0863 - learning_rate: 2.5000e-04\n",
      "Epoch 164/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0746 - val_accuracy: 1.0000 - val_loss: 0.0853 - learning_rate: 2.5000e-04\n",
      "Epoch 165/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0738 - val_accuracy: 1.0000 - val_loss: 0.0846 - learning_rate: 2.5000e-04\n",
      "Epoch 166/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0735 - val_accuracy: 1.0000 - val_loss: 0.0844 - learning_rate: 2.5000e-04\n",
      "Epoch 167/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0730 - val_accuracy: 1.0000 - val_loss: 0.0840 - learning_rate: 2.5000e-04\n",
      "Epoch 168/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0726 - val_accuracy: 1.0000 - val_loss: 0.0838 - learning_rate: 2.5000e-04\n",
      "Epoch 169/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0727 - val_accuracy: 0.9875 - val_loss: 0.0860 - learning_rate: 2.5000e-04\n",
      "Epoch 170/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0721 - val_accuracy: 0.9875 - val_loss: 0.0866 - learning_rate: 2.5000e-04\n",
      "Epoch 171/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0715 - val_accuracy: 0.9875 - val_loss: 0.0864 - learning_rate: 2.5000e-04\n",
      "Epoch 172/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0711 - val_accuracy: 0.9875 - val_loss: 0.0863 - learning_rate: 2.5000e-04\n",
      "Epoch 173/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0710 - val_accuracy: 0.9875 - val_loss: 0.0850 - learning_rate: 2.5000e-04\n",
      "Epoch 174/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0703 - val_accuracy: 0.9875 - val_loss: 0.0845 - learning_rate: 2.5000e-04\n",
      "Epoch 175/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0710 - val_accuracy: 0.9875 - val_loss: 0.0826 - learning_rate: 2.5000e-04\n",
      "Epoch 176/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0696 - val_accuracy: 0.9875 - val_loss: 0.0817 - learning_rate: 2.5000e-04\n",
      "Epoch 177/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0696 - val_accuracy: 0.9875 - val_loss: 0.0816 - learning_rate: 2.5000e-04\n",
      "Epoch 178/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0687 - val_accuracy: 0.9875 - val_loss: 0.0816 - learning_rate: 2.5000e-04\n",
      "Epoch 179/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0685 - val_accuracy: 0.9875 - val_loss: 0.0806 - learning_rate: 2.5000e-04\n",
      "Epoch 180/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0682 - val_accuracy: 0.9875 - val_loss: 0.0801 - learning_rate: 2.5000e-04\n",
      "Epoch 181/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0677 - val_accuracy: 0.9875 - val_loss: 0.0800 - learning_rate: 2.5000e-04\n",
      "Epoch 182/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0673 - val_accuracy: 0.9875 - val_loss: 0.0789 - learning_rate: 2.5000e-04\n",
      "Epoch 183/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0669 - val_accuracy: 1.0000 - val_loss: 0.0778 - learning_rate: 2.5000e-04\n",
      "Epoch 184/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0665 - val_accuracy: 1.0000 - val_loss: 0.0772 - learning_rate: 2.5000e-04\n",
      "Epoch 185/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0660 - val_accuracy: 1.0000 - val_loss: 0.0766 - learning_rate: 2.5000e-04\n",
      "Epoch 186/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0659 - val_accuracy: 1.0000 - val_loss: 0.0756 - learning_rate: 2.5000e-04\n",
      "Epoch 187/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0655 - val_accuracy: 1.0000 - val_loss: 0.0743 - learning_rate: 2.5000e-04\n",
      "Epoch 188/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0651 - val_accuracy: 1.0000 - val_loss: 0.0732 - learning_rate: 2.5000e-04\n",
      "Epoch 189/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0655 - val_accuracy: 1.0000 - val_loss: 0.0703 - learning_rate: 2.5000e-04\n",
      "Epoch 190/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0646 - val_accuracy: 1.0000 - val_loss: 0.0707 - learning_rate: 2.5000e-04\n",
      "Epoch 191/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0639 - val_accuracy: 1.0000 - val_loss: 0.0698 - learning_rate: 2.5000e-04\n",
      "Epoch 192/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0635 - val_accuracy: 1.0000 - val_loss: 0.0693 - learning_rate: 2.5000e-04\n",
      "Epoch 193/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0632 - val_accuracy: 1.0000 - val_loss: 0.0687 - learning_rate: 2.5000e-04\n",
      "Epoch 194/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0626 - val_accuracy: 1.0000 - val_loss: 0.0682 - learning_rate: 2.5000e-04\n",
      "Epoch 195/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0623 - val_accuracy: 1.0000 - val_loss: 0.0679 - learning_rate: 2.5000e-04\n",
      "Epoch 196/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0622 - val_accuracy: 1.0000 - val_loss: 0.0674 - learning_rate: 2.5000e-04\n",
      "Epoch 197/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0615 - val_accuracy: 1.0000 - val_loss: 0.0670 - learning_rate: 2.5000e-04\n",
      "Epoch 198/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0613 - val_accuracy: 1.0000 - val_loss: 0.0666 - learning_rate: 2.5000e-04\n",
      "Epoch 199/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0608 - val_accuracy: 1.0000 - val_loss: 0.0662 - learning_rate: 2.5000e-04\n",
      "Epoch 200/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0604 - val_accuracy: 1.0000 - val_loss: 0.0657 - learning_rate: 2.5000e-04\n",
      "\n",
      "Evaluating Optimized MLP...\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000230E170B2E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\n",
      "ğŸ“Š MLP OPTIMIZED RESULTS:\n",
      "Accuracy: 0.9649 (96.49%)\n",
      "Precision: 0.9810\n",
      "Recall (Sensitivity): 0.9626\n",
      "F1-Score: 0.9717\n",
      "False Negative Rate: 0.0374\n",
      "Confusion Matrix:\n",
      "[[ 62   2]\n",
      " [  4 103]]\n",
      "\n",
      "ğŸ” COMPARISON WITH REPRODUCTION:\n",
      "Accuracy improvement: +0.0000\n",
      "Recall improvement: +0.0093\n",
      "FNR improvement: +0.0093\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 2. MLP OPTIMIZED MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MLP OPTIMIZED MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Create optimized MLP with regularization and improvements\n",
    "mlp_optimized = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X_train_scaled.shape[1],), \n",
    "          kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "mlp_optimized.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Optimized MLP Architecture Summary:\")\n",
    "mlp_optimized.summary()\n",
    "\n",
    "print(f\"\\nOptimization Improvements:\")\n",
    "print(f\"- Added L2 regularization (0.001)\")\n",
    "print(f\"- Added Batch Normalization\")\n",
    "print(f\"- Added Dropout (0.3, 0.3, 0.2)\")\n",
    "print(f\"- Reduced learning rate (0.001)\")\n",
    "print(f\"- Smaller batch size (32)\")\n",
    "print(f\"- Early stopping and learning rate reduction\")\n",
    "\n",
    "# Callbacks for optimization\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=15, restore_best_weights=True, monitor='val_loss'),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "# Train optimized model\n",
    "print(\"\\nTraining optimized MLP...\")\n",
    "history_optimized = mlp_optimized.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    batch_size=32,\n",
    "    epochs=200,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Evaluate optimized model\n",
    "print(\"\\nEvaluating Optimized MLP...\")\n",
    "y_pred_mlp_optimized = (mlp_optimized.predict(X_test_scaled) > 0.5).astype(\"int32\")\n",
    "acc_mlp_optimized = accuracy_score(y_test, y_pred_mlp_optimized)\n",
    "\n",
    "# Calculate additional metrics\n",
    "precision_opt, recall_opt, f1_opt, _ = precision_recall_fscore_support(y_test, y_pred_mlp_optimized, average='binary')\n",
    "cm_opt = confusion_matrix(y_test, y_pred_mlp_optimized)\n",
    "tn_opt, fp_opt, fn_opt, tp_opt = cm_opt.ravel()\n",
    "\n",
    "print(f\"\\nğŸ“Š MLP OPTIMIZED RESULTS:\")\n",
    "print(f\"Accuracy: {acc_mlp_optimized:.4f} ({acc_mlp_optimized*100:.2f}%)\")\n",
    "print(f\"Precision: {precision_opt:.4f}\")\n",
    "print(f\"Recall (Sensitivity): {recall_opt:.4f}\")\n",
    "print(f\"F1-Score: {f1_opt:.4f}\")\n",
    "print(f\"False Negative Rate: {fn_opt/(fn_opt+tp_opt):.4f}\")\n",
    "print(f\"Confusion Matrix:\")\n",
    "print(cm_opt)\n",
    "\n",
    "# Compare with reproduction\n",
    "print(f\"\\nğŸ” COMPARISON WITH REPRODUCTION:\")\n",
    "print(f\"Accuracy improvement: {acc_mlp_optimized - acc_mlp_paper:+.4f}\")\n",
    "print(f\"Recall improvement: {recall_opt - recall_mlp:+.4f}\")\n",
    "print(f\"FNR improvement: {(fn/(fn+tp)) - (fn_opt/(fn_opt+tp_opt)):+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f676e90e",
   "metadata": {},
   "source": [
    "MLP Hyper-OptimisÃ©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5135260e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MLP HYPER-OPTIMIZED MODEL\n",
      "======================================================================\n",
      "Implementing advanced optimization strategies...\n",
      "Final training set: 338 samples\n",
      "Validation set: 60 samples\n",
      "Test set: 171 samples\n",
      "Hyper-Optimized MLP Architecture Summary:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">15,872</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_3           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">196,992</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_4           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_5           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_6           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense_12 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚        \u001b[38;5;34m15,872\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_3           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚         \u001b[38;5;34m2,048\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_13 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)            â”‚       \u001b[38;5;34m196,992\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_4           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)            â”‚         \u001b[38;5;34m1,536\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_14 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚        \u001b[38;5;34m98,560\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_5           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m1,024\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_15 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚        \u001b[38;5;34m32,896\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_6           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_16 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m129\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">349,569</span> (1.33 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m349,569\u001b[0m (1.33 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">347,009</span> (1.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m347,009\u001b[0m (1.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,560</span> (10.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,560\u001b[0m (10.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¯ ADVANCED OPTIMIZATION FEATURES:\n",
      "- Advanced architecture: [512, 384, 256, 128]\n",
      "- ELU activation for better gradient flow\n",
      "- Nadam optimizer with adaptive learning\n",
      "- Progressive dropout reduction: 0.4 â†’ 0.28\n",
      "- L2 regularization: 0.0005\n",
      "- Batch size: 16 for better gradient estimation\n",
      "- Learning rate: 0.0005 for stable convergence\n",
      "- Separate validation set for precise early stopping\n",
      "\n",
      "Class weights for imbalance handling: {0: np.float64(1.3412698412698412), 1: np.float64(0.7971698113207547)}\n",
      "\n",
      "ğŸš€ Training Hyper-Optimized MLP...\n",
      "Epoch 1/300\n",
      "\u001b[1m19/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7350 - loss: 1.0352 - precision: 0.8142 - recall: 0.7145"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.8314 - loss: 0.8520 - precision: 0.9189 - recall: 0.8019 - val_accuracy: 0.9833 - val_loss: 0.6849 - val_precision: 1.0000 - val_recall: 0.9737 - learning_rate: 5.0000e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9201 - loss: 0.6641 - precision: 0.9648 - recall: 0.9057 - val_accuracy: 0.9833 - val_loss: 0.6202 - val_precision: 1.0000 - val_recall: 0.9737 - learning_rate: 5.0000e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m18/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9469 - loss: 0.6268 - precision: 0.9469 - recall: 0.9662 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9556 - loss: 0.6196 - precision: 0.9713 - recall: 0.9575 - val_accuracy: 1.0000 - val_loss: 0.5816 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9467 - loss: 0.6052 - precision: 0.9619 - recall: 0.9528 - val_accuracy: 0.9833 - val_loss: 0.5623 - val_precision: 1.0000 - val_recall: 0.9737 - learning_rate: 5.0000e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9527 - loss: 0.5770 - precision: 0.9757 - recall: 0.9481 - val_accuracy: 1.0000 - val_loss: 0.5310 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9734 - loss: 0.5605 - precision: 0.9810 - recall: 0.9764 - val_accuracy: 1.0000 - val_loss: 0.5221 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9763 - loss: 0.5428 - precision: 0.9857 - recall: 0.9764 - val_accuracy: 1.0000 - val_loss: 0.5160 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9704 - loss: 0.5366 - precision: 0.9764 - recall: 0.9764 - val_accuracy: 0.9833 - val_loss: 0.5201 - val_precision: 1.0000 - val_recall: 0.9737 - learning_rate: 5.0000e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9645 - loss: 0.5540 - precision: 0.9808 - recall: 0.9623 - val_accuracy: 0.9833 - val_loss: 0.5165 - val_precision: 1.0000 - val_recall: 0.9737 - learning_rate: 5.0000e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9822 - loss: 0.5104 - precision: 0.9858 - recall: 0.9858 - val_accuracy: 0.9833 - val_loss: 0.5061 - val_precision: 1.0000 - val_recall: 0.9737 - learning_rate: 5.0000e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9793 - loss: 0.5064 - precision: 0.9952 - recall: 0.9717 - val_accuracy: 0.9833 - val_loss: 0.4964 - val_precision: 1.0000 - val_recall: 0.9737 - learning_rate: 5.0000e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9793 - loss: 0.5153 - precision: 0.9952 - recall: 0.9717 - val_accuracy: 1.0000 - val_loss: 0.4810 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9852 - loss: 0.5021 - precision: 0.9905 - recall: 0.9858 - val_accuracy: 1.0000 - val_loss: 0.4810 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9941 - loss: 0.4802 - precision: 1.0000 - recall: 0.9906 - val_accuracy: 0.9833 - val_loss: 0.4823 - val_precision: 1.0000 - val_recall: 0.9737 - learning_rate: 5.0000e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9941 - loss: 0.4811 - precision: 1.0000 - recall: 0.9906 - val_accuracy: 0.9833 - val_loss: 0.4842 - val_precision: 1.0000 - val_recall: 0.9737 - learning_rate: 5.0000e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.4716 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9833 - val_loss: 0.4811 - val_precision: 1.0000 - val_recall: 0.9737 - learning_rate: 5.0000e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9822 - loss: 0.4923 - precision: 0.9858 - recall: 0.9858 - val_accuracy: 0.9833 - val_loss: 0.4826 - val_precision: 1.0000 - val_recall: 0.9737 - learning_rate: 5.0000e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9852 - loss: 0.4790 - precision: 0.9952 - recall: 0.9811 - val_accuracy: 1.0000 - val_loss: 0.4650 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9911 - loss: 0.4720 - precision: 0.9906 - recall: 0.9953 - val_accuracy: 0.9833 - val_loss: 0.4802 - val_precision: 1.0000 - val_recall: 0.9737 - learning_rate: 5.0000e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9941 - loss: 0.4588 - precision: 1.0000 - recall: 0.9906 - val_accuracy: 0.9833 - val_loss: 0.4688 - val_precision: 1.0000 - val_recall: 0.9737 - learning_rate: 5.0000e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9970 - loss: 0.4505 - precision: 1.0000 - recall: 0.9953 - val_accuracy: 0.9833 - val_loss: 0.4681 - val_precision: 1.0000 - val_recall: 0.9737 - learning_rate: 5.0000e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9941 - loss: 0.4615 - precision: 0.9953 - recall: 0.9953 - val_accuracy: 0.9667 - val_loss: 0.5210 - val_precision: 1.0000 - val_recall: 0.9474 - learning_rate: 5.0000e-04\n",
      "Epoch 23/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9882 - loss: 0.4691 - precision: 0.9906 - recall: 0.9906 - val_accuracy: 0.9667 - val_loss: 0.4849 - val_precision: 1.0000 - val_recall: 0.9474 - learning_rate: 5.0000e-04\n",
      "Epoch 24/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9941 - loss: 0.4472 - precision: 1.0000 - recall: 0.9906 - val_accuracy: 0.9833 - val_loss: 0.4783 - val_precision: 1.0000 - val_recall: 0.9737 - learning_rate: 5.0000e-04\n",
      "Epoch 25/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9822 - loss: 0.4641 - precision: 0.9858 - recall: 0.9858 - val_accuracy: 0.9833 - val_loss: 0.5288 - val_precision: 1.0000 - val_recall: 0.9737 - learning_rate: 5.0000e-04\n",
      "Epoch 26/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9911 - loss: 0.4419 - precision: 1.0000 - recall: 0.9858 - val_accuracy: 0.9833 - val_loss: 0.4727 - val_precision: 1.0000 - val_recall: 0.9737 - learning_rate: 5.0000e-04\n",
      "Epoch 27/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9941 - loss: 0.4372 - precision: 0.9953 - recall: 0.9953 - val_accuracy: 0.9833 - val_loss: 0.4674 - val_precision: 1.0000 - val_recall: 0.9737 - learning_rate: 5.0000e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.4325 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9833 - val_loss: 0.4561 - val_precision: 1.0000 - val_recall: 0.9737 - learning_rate: 5.0000e-04\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\n",
      "ğŸ§ª Evaluating Hyper-Optimized MLP...\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000230E3ABD620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000230E3ABD620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\n",
      "ğŸ“Š MLP HYPER-OPTIMIZED RESULTS:\n",
      "Accuracy: 0.9708 (97.08%)\n",
      "Precision: 0.9904\n",
      "Recall (Sensitivity): 0.9626 â­\n",
      "F1-Score: 0.9763\n",
      "Specificity: 0.9844\n",
      "False Negative Rate: 0.0374 âš ï¸\n",
      "False Positive Rate: 0.0156\n",
      "AUC-ROC: 0.9978\n",
      "AUC-PR: 0.9987\n",
      "Confusion Matrix:\n",
      "[[ 63   1]\n",
      " [  4 103]]\n",
      "\n",
      "ğŸ” DETAILED COMPARISON WITH PREVIOUS MODELS:\n",
      "Metric               MLP Paper    MLP Optimized   MLP Hyper-Optimized \n",
      "----------------------------------------------------------------------\n",
      "Accuracy             0.9649        0.9649           0.9708\n",
      "Recall               0.9533        0.9626           0.9626\n",
      "FNR                  0.0467        0.0374           0.0374\n",
      "Precision            0.9903        0.9810           0.9904\n",
      "F1-Score             0.9714        0.9717           0.9763\n",
      "\n",
      "ğŸ¯ KEY IMPROVEMENTS:\n",
      "Recall improvement: +0.0000\n",
      "FNR reduction: +0.0000\n",
      "âœ… GOOD: FNR < 5% - Acceptable for clinical use\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¡ RECOMMENDATIONS FOR CLINICAL USE:\n",
      "âœ… This model is SUITABLE for clinical use with monitoring\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 2bis. MLP HYPER-OPTIMIZED MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MLP HYPER-OPTIMIZED MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# StratÃ©gie d'optimisation avancÃ©e\n",
    "print(\"Implementing advanced optimization strategies...\")\n",
    "\n",
    "# 1. Split supplÃ©mentaire pour validation\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train_scaled, y_train, test_size=0.15, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"Final training set: {X_train_final.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test_scaled.shape[0]} samples\")\n",
    "\n",
    "# 2. Architecture avancÃ©e avec recherche d'hyperparamÃ¨tres\n",
    "def create_advanced_mlp(learning_rate=0.001, dropout_rate=0.4, l2_reg=0.0001):\n",
    "    model = Sequential([\n",
    "        # Couche d'entrÃ©e avec plus de neurones\n",
    "        Dense(512, activation='relu', input_shape=(X_train_scaled.shape[1],),\n",
    "              kernel_regularizer=l1_l2(l1=0, l2=l2_reg)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        \n",
    "        # Couches intermÃ©diaires avec dÃ©croissance progressive\n",
    "        Dense(384, activation='elu', kernel_regularizer=l1_l2(l1=0, l2=l2_reg)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate * 0.9),\n",
    "        \n",
    "        Dense(256, activation='elu', kernel_regularizer=l1_l2(l1=0, l2=l2_reg)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate * 0.8),\n",
    "        \n",
    "        Dense(128, activation='elu', kernel_regularizer=l1_l2(l1=0, l2=l2_reg)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate * 0.7),\n",
    "        \n",
    "        # Couche de sortie\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Optimiseur avancÃ©\n",
    "    optimizer = Nadam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', 'precision', 'recall']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 3. CrÃ©ation du modÃ¨le hyper-optimisÃ©\n",
    "mlp_hyper = create_advanced_mlp(\n",
    "    learning_rate=0.0005,  # Learning rate plus bas\n",
    "    dropout_rate=0.4,      # Dropout plus agressif\n",
    "    l2_reg=0.0005         # RÃ©gularisation renforcÃ©e\n",
    ")\n",
    "\n",
    "print(\"Hyper-Optimized MLP Architecture Summary:\")\n",
    "mlp_hyper.summary()\n",
    "\n",
    "print(f\"\\nğŸ¯ ADVANCED OPTIMIZATION FEATURES:\")\n",
    "print(f\"- Advanced architecture: [512, 384, 256, 128]\")\n",
    "print(f\"- ELU activation for better gradient flow\")\n",
    "print(f\"- Nadam optimizer with adaptive learning\")\n",
    "print(f\"- Progressive dropout reduction: 0.4 â†’ 0.28\")\n",
    "print(f\"- L2 regularization: 0.0005\")\n",
    "print(f\"- Batch size: 16 for better gradient estimation\")\n",
    "print(f\"- Learning rate: 0.0005 for stable convergence\")\n",
    "print(f\"- Separate validation set for precise early stopping\")\n",
    "\n",
    "# 4. Callbacks avancÃ©s\n",
    "advanced_callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_recall',        # On maximise le recall pour dÃ©tecter le cancer\n",
    "        patience=25,\n",
    "        restore_best_weights=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=15,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        'best_mlp_model.h5',\n",
    "        monitor='val_recall',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=0\n",
    "    )\n",
    "]\n",
    "\n",
    "# 5. EntraÃ®nement avec donnÃ©es balancÃ©es (class weights)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train_final),\n",
    "    y=y_train_final\n",
    ")\n",
    "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "print(f\"\\nClass weights for imbalance handling: {class_weight_dict}\")\n",
    "\n",
    "print(\"\\nğŸš€ Training Hyper-Optimized MLP...\")\n",
    "history_hyper = mlp_hyper.fit(\n",
    "    X_train_final, y_train_final,\n",
    "    batch_size=16,  # Batch size plus petit\n",
    "    epochs=300,\n",
    "    validation_data=(X_val, y_val),  # Validation sÃ©parÃ©e\n",
    "    class_weight=class_weight_dict,  # Gestion du dÃ©sÃ©quilibre\n",
    "    verbose=1,\n",
    "    callbacks=advanced_callbacks\n",
    ")\n",
    "\n",
    "# 6. Ã‰valuation approfondie\n",
    "print(\"\\nğŸ§ª Evaluating Hyper-Optimized MLP...\")\n",
    "\n",
    "# Charger le meilleur modÃ¨le sauvegardÃ©\n",
    "mlp_hyper.load_weights('best_mlp_model.h5')\n",
    "\n",
    "y_pred_mlp_hyper = (mlp_hyper.predict(X_test_scaled) > 0.5).astype(\"int32\")\n",
    "y_pred_proba_hyper = mlp_hyper.predict(X_test_scaled).flatten()\n",
    "\n",
    "# MÃ©triques complÃ¨tes\n",
    "acc_hyper = accuracy_score(y_test, y_pred_mlp_hyper)\n",
    "precision_hyper, recall_hyper, f1_hyper, _ = precision_recall_fscore_support(y_test, y_pred_mlp_hyper, average='binary')\n",
    "cm_hyper = confusion_matrix(y_test, y_pred_mlp_hyper)\n",
    "tn_hyper, fp_hyper, fn_hyper, tp_hyper = cm_hyper.ravel()\n",
    "\n",
    "# MÃ©triques avancÃ©es\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "\n",
    "auc_hyper = roc_auc_score(y_test, y_pred_proba_hyper)\n",
    "precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_proba_hyper)\n",
    "auc_pr = auc(recall_curve, precision_curve)\n",
    "\n",
    "# Calcul des taux spÃ©cifiques\n",
    "fnr_hyper = fn_hyper / (fn_hyper + tp_hyper)\n",
    "fpr_hyper = fp_hyper / (fp_hyper + tn_hyper)\n",
    "specificity_hyper = tn_hyper / (tn_hyper + fp_hyper)\n",
    "\n",
    "print(f\"\\nğŸ“Š MLP HYPER-OPTIMIZED RESULTS:\")\n",
    "print(f\"Accuracy: {acc_hyper:.4f} ({acc_hyper*100:.2f}%)\")\n",
    "print(f\"Precision: {precision_hyper:.4f}\")\n",
    "print(f\"Recall (Sensitivity): {recall_hyper:.4f} â­\")\n",
    "print(f\"F1-Score: {f1_hyper:.4f}\")\n",
    "print(f\"Specificity: {specificity_hyper:.4f}\")\n",
    "print(f\"False Negative Rate: {fnr_hyper:.4f} âš ï¸\")\n",
    "print(f\"False Positive Rate: {fpr_hyper:.4f}\")\n",
    "print(f\"AUC-ROC: {auc_hyper:.4f}\")\n",
    "print(f\"AUC-PR: {auc_pr:.4f}\")\n",
    "print(f\"Confusion Matrix:\")\n",
    "print(cm_hyper)\n",
    "\n",
    "# 7. Comparaison dÃ©taillÃ©e\n",
    "print(f\"\\nğŸ” DETAILED COMPARISON WITH PREVIOUS MODELS:\")\n",
    "print(f\"{'Metric':<20} {'MLP Paper':<12} {'MLP Optimized':<15} {'MLP Hyper-Optimized':<20}\")\n",
    "print(f\"{'-'*70}\")\n",
    "print(f\"{'Accuracy':<20} {acc_mlp_paper:.4f}        {acc_mlp_optimized:.4f}           {acc_hyper:.4f}\")\n",
    "print(f\"{'Recall':<20} {recall_mlp:.4f}        {recall_opt:.4f}           {recall_hyper:.4f}\")\n",
    "print(f\"{'FNR':<20} {fn/(fn+tp):.4f}        {fn_opt/(fn_opt+tp_opt):.4f}           {fnr_hyper:.4f}\")\n",
    "print(f\"{'Precision':<20} {precision_mlp:.4f}        {precision_opt:.4f}           {precision_hyper:.4f}\")\n",
    "print(f\"{'F1-Score':<20} {f1_mlp:.4f}        {f1_opt:.4f}           {f1_hyper:.4f}\")\n",
    "\n",
    "# 8. Analyse des amÃ©liorations\n",
    "improvement_recall = recall_hyper - max(recall_mlp, recall_opt)\n",
    "improvement_fnr = min(fn/(fn+tp), fn_opt/(fn_opt+tp_opt)) - fnr_hyper\n",
    "\n",
    "print(f\"\\nğŸ¯ KEY IMPROVEMENTS:\")\n",
    "print(f\"Recall improvement: {improvement_recall:+.4f}\")\n",
    "print(f\"FNR reduction: {improvement_fnr:+.4f}\")\n",
    "\n",
    "if fnr_hyper < 0.03:\n",
    "    print(\"âœ… EXCELLENT: FNR < 3% - Very low missed cancer cases!\")\n",
    "elif fnr_hyper < 0.05:\n",
    "    print(\"âœ… GOOD: FNR < 5% - Acceptable for clinical use\")\n",
    "else:\n",
    "    print(\"âš ï¸  NEEDS IMPROVEMENT: FNR > 5% - Consider additional strategies\")\n",
    "\n",
    "# 9. Visualisation de l'apprentissage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history_hyper.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_hyper.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history_hyper.history['loss'], label='Training Loss')\n",
    "plt.plot(history_hyper.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history_hyper.history['recall'], label='Training Recall')\n",
    "plt.plot(history_hyper.history['val_recall'], label='Validation Recall')\n",
    "plt.title('Model Recall')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nğŸ’¡ RECOMMENDATIONS FOR CLINICAL USE:\")\n",
    "if recall_hyper > 0.98 and fnr_hyper < 0.02:\n",
    "    print(\"âœ… This model is HIGHLY SUITABLE for clinical deployment\")\n",
    "elif recall_hyper > 0.95 and fnr_hyper < 0.05:\n",
    "    print(\"âœ… This model is SUITABLE for clinical use with monitoring\")\n",
    "else:\n",
    "    print(\"âš ï¸  This model needs further optimization before clinical use\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852cb964",
   "metadata": {},
   "source": [
    "MLP Focus Recall (Cancer Detection Optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c53bc01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MLP RECALL-OPTIMIZED MODEL - CANCER DETECTION FOCUS\n",
      "======================================================================\n",
      "Recall-Optimized MLP Architecture Summary:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,600</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_7           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,400</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">450</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">270,450</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_8           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">450</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,800</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">450</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">135,300</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_9           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,200</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">45,150</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_10          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">151</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense_17 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)            â”‚        \u001b[38;5;34m18,600\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_7           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)            â”‚         \u001b[38;5;34m2,400\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_18 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m450\u001b[0m)            â”‚       \u001b[38;5;34m270,450\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_8           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m450\u001b[0m)            â”‚         \u001b[38;5;34m1,800\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m450\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_19 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            â”‚       \u001b[38;5;34m135,300\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_9           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            â”‚         \u001b[38;5;34m1,200\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_20 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            â”‚        \u001b[38;5;34m45,150\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_10          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            â”‚           \u001b[38;5;34m600\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_21 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m151\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">475,651</span> (1.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m475,651\u001b[0m (1.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">472,651</span> (1.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m472,651\u001b[0m (1.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,000</span> (11.72 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,000\u001b[0m (11.72 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¯ RECALL-OPTIMIZATION STRATEGY:\n",
      "- Custom loss function: 3x penalty for false negatives\n",
      "- Wider architecture: [600, 450, 300, 150]\n",
      "- Lower dropout (0.3) for increased sensitivity\n",
      "- Combined L1 + L2 regularization\n",
      "- Lower learning rate (0.0002) for stable training\n",
      "- Early stopping on VAL_RECALL (max mode)\n",
      "\n",
      "Class weights for recall optimization: {0: 1.0, 1: 2.5}\n",
      "\n",
      "ğŸš€ Training Recall-Optimized MLP...\n",
      "Epoch 1/400\n",
      "\u001b[1m16/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7326 - loss: 4.4161 - precision: 0.8071 - recall: 0.7178"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8373 - loss: 3.8385 - precision: 0.9153 - recall: 0.8160 - val_accuracy: 0.9667 - val_loss: 2.6097 - val_precision: 1.0000 - val_recall: 0.9474 - learning_rate: 2.0000e-04\n",
      "Epoch 2/400\n",
      "\u001b[1m15/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9227 - loss: 2.8066 - precision: 0.9322 - recall: 0.9374 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9438 - loss: 2.8441 - precision: 0.9662 - recall: 0.9434 - val_accuracy: 0.9833 - val_loss: 2.4309 - val_precision: 1.0000 - val_recall: 0.9737 - learning_rate: 2.0000e-04\n",
      "Epoch 3/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9645 - loss: 2.5673 - precision: 0.9630 - recall: 0.9811 - val_accuracy: 0.9833 - val_loss: 2.3626 - val_precision: 1.0000 - val_recall: 0.9737 - learning_rate: 2.0000e-04\n",
      "Epoch 4/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9615 - loss: 2.5411 - precision: 0.9585 - recall: 0.9811 - val_accuracy: 0.9833 - val_loss: 2.3384 - val_precision: 1.0000 - val_recall: 0.9737 - learning_rate: 2.0000e-04\n",
      "Epoch 5/400\n",
      "\u001b[1m13/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9656 - loss: 2.3679 - precision: 0.9455 - recall: 1.0000 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9704 - loss: 2.4353 - precision: 0.9633 - recall: 0.9906 - val_accuracy: 1.0000 - val_loss: 2.2972 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\n",
      "Epoch 6/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9734 - loss: 2.3957 - precision: 0.9593 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.2648 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\n",
      "Epoch 7/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9704 - loss: 2.3721 - precision: 0.9550 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.2597 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\n",
      "Epoch 8/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9704 - loss: 2.3558 - precision: 0.9633 - recall: 0.9906 - val_accuracy: 1.0000 - val_loss: 2.2488 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\n",
      "Epoch 9/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9675 - loss: 2.3800 - precision: 0.9589 - recall: 0.9906 - val_accuracy: 1.0000 - val_loss: 2.2344 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\n",
      "Epoch 10/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9704 - loss: 2.3369 - precision: 0.9550 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.2238 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\n",
      "Epoch 11/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9882 - loss: 2.3264 - precision: 0.9815 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.2207 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\n",
      "Epoch 12/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9734 - loss: 2.3136 - precision: 0.9593 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.2105 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\n",
      "Epoch 13/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9852 - loss: 2.2808 - precision: 0.9770 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.2027 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\n",
      "Epoch 14/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9734 - loss: 2.2944 - precision: 0.9635 - recall: 0.9953 - val_accuracy: 1.0000 - val_loss: 2.1995 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\n",
      "Epoch 15/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9793 - loss: 2.2837 - precision: 0.9680 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.1982 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\n",
      "Epoch 16/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9763 - loss: 2.2887 - precision: 0.9679 - recall: 0.9953 - val_accuracy: 1.0000 - val_loss: 2.1918 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\n",
      "Epoch 17/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9822 - loss: 2.2775 - precision: 0.9725 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.1794 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\n",
      "Epoch 18/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9793 - loss: 2.2608 - precision: 0.9680 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.1747 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\n",
      "Epoch 19/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9822 - loss: 2.2557 - precision: 0.9725 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.1725 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\n",
      "Epoch 20/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9763 - loss: 2.2587 - precision: 0.9636 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.1680 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\n",
      "Epoch 21/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9822 - loss: 2.2536 - precision: 0.9725 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.1630 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\n",
      "Epoch 22/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9763 - loss: 2.2564 - precision: 0.9679 - recall: 0.9953 - val_accuracy: 1.0000 - val_loss: 2.1585 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\n",
      "Epoch 23/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9852 - loss: 2.2412 - precision: 0.9770 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.1524 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\n",
      "Epoch 24/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9822 - loss: 2.2175 - precision: 0.9725 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.1503 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\n",
      "Epoch 25/400\n",
      "\u001b[1m14/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9681 - loss: 2.2633 - precision: 0.9490 - recall: 1.0000 \n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9852 - loss: 2.2309 - precision: 0.9770 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.1443 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\n",
      "Epoch 26/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9882 - loss: 2.2197 - precision: 0.9815 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.1427 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 27/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9793 - loss: 2.2087 - precision: 0.9680 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.1410 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 28/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9882 - loss: 2.2036 - precision: 0.9815 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.1396 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 29/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9882 - loss: 2.2109 - precision: 0.9815 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.1372 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 30/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9763 - loss: 2.2008 - precision: 0.9636 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.1346 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 31/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9911 - loss: 2.2065 - precision: 0.9860 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.1342 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 32/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9852 - loss: 2.1991 - precision: 0.9770 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.1295 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 33/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9822 - loss: 2.2082 - precision: 0.9725 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.1260 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 34/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9852 - loss: 2.1873 - precision: 0.9770 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.1251 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 35/400\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9882 - loss: 2.1907 - precision: 0.9815 - recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.1242 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "\n",
      "ğŸ§ª Evaluating Recall-Optimized MLP...\n",
      "Searching for optimal threshold to maximize recall...\n",
      "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "âœ… Optimal threshold found: 0.100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\n",
      "ğŸ“Š MLP RECALL-OPTIMIZED RESULTS (Threshold: 0.100):\n",
      "Accuracy: 0.9357 (93.57%)\n",
      "Precision: 0.9068\n",
      "Recall (Sensitivity): 1.0000 ğŸ¯\n",
      "F1-Score: 0.9511\n",
      "Specificity: 0.8281\n",
      "False Negative Rate: 0.0000 âš ï¸\n",
      "False Positive Rate: 0.1719\n",
      "AUC-ROC: 0.9980\n",
      "Confusion Matrix:\n",
      "[[ 53  11]\n",
      " [  0 107]]\n",
      "\n",
      "ğŸ” ULTIMATE COMPARISON:\n",
      "Metric               MLP Paper    MLP Optimized   MLP Hyper       MLP Recall     \n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy             0.9649        0.9649           0.9708           0.9357\n",
      "Recall â­             0.9533        0.9626           0.9626           1.0000\n",
      "FNR âš ï¸               0.0467        0.0374           0.0374           0.0000\n",
      "Precision            0.9903        0.9810           0.9904           0.9068\n",
      "\n",
      "ğŸ¥ CLINICAL IMPACT ANALYSIS:\n",
      "Current missed cancer cases (FNR): 0.0%\n",
      "âœ… EXCELLENT: Less than 2% missed cancer cases - IDEAL for clinical use!\n",
      "   This could save approximately 2 more patients per 100 compared to previous models\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¡ FINAL RECOMMENDATION:\n",
      "ğŸ‰ DEPLOY RECALL-OPTIMIZED MODEL - Maximum cancer detection achieved!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 2ter. MLP RECALL-OPTIMIZED MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MLP RECALL-OPTIMIZED MODEL - CANCER DETECTION FOCUS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Fonction de perte customisÃ©e pour maximiser le Recall\n",
    "def recall_focused_loss(y_true, y_pred):\n",
    "    \"\"\"Loss function that penalizes false negatives more heavily\"\"\"\n",
    "    # Binary cross entropy de base\n",
    "    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    # PÃ©nalitÃ© supplÃ©mentaire pour les faux nÃ©gatifs\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    # Calcul des faux nÃ©gatifs\n",
    "    false_negatives = y_true * (1.0 - y_pred)  # Vrai positif mal classÃ©\n",
    "    \n",
    "    # PÃ©nalitÃ© 3x plus forte pour les faux nÃ©gatifs\n",
    "    fn_penalty = tf.reduce_mean(false_negatives) * 3.0\n",
    "    \n",
    "    return bce + fn_penalty\n",
    "\n",
    "def create_recall_optimized_mlp(learning_rate=0.0003, dropout_rate=0.35):\n",
    "    model = Sequential([\n",
    "        # Architecture plus large pour capturer plus de patterns\n",
    "        Dense(600, activation='elu', input_shape=(X_train_scaled.shape[1],),\n",
    "              kernel_regularizer=l1_l2(l1=0.0001, l2=0.0002)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        \n",
    "        Dense(450, activation='elu', kernel_regularizer=l1_l2(l1=0.0001, l2=0.0002)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate * 0.85),\n",
    "        \n",
    "        Dense(300, activation='elu', kernel_regularizer=l1_l2(l1=0.0001, l2=0.0002)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate * 0.7),\n",
    "        \n",
    "        Dense(150, activation='elu', kernel_regularizer=l1_l2(l1=0.0001, l2=0.0002)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate * 0.6),\n",
    "        \n",
    "        # Couche de sortie\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    optimizer = Nadam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=recall_focused_loss,  # Utilisation de la loss customisÃ©e\n",
    "        metrics=['accuracy', 'precision', 'recall']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# CrÃ©ation du modÃ¨le optimisÃ© Recall\n",
    "mlp_recall = create_recall_optimized_mlp(\n",
    "    learning_rate=0.0002,\n",
    "    dropout_rate=0.3  # Moins de dropout pour plus de sensibilitÃ©\n",
    ")\n",
    "\n",
    "print(\"Recall-Optimized MLP Architecture Summary:\")\n",
    "mlp_recall.summary()\n",
    "\n",
    "print(f\"\\nğŸ¯ RECALL-OPTIMIZATION STRATEGY:\")\n",
    "print(f\"- Custom loss function: 3x penalty for false negatives\")\n",
    "print(f\"- Wider architecture: [600, 450, 300, 150]\")\n",
    "print(f\"- Lower dropout (0.3) for increased sensitivity\")\n",
    "print(f\"- Combined L1 + L2 regularization\")\n",
    "print(f\"- Lower learning rate (0.0002) for stable training\")\n",
    "print(f\"- Early stopping on VAL_RECALL (max mode)\")\n",
    "\n",
    "# Callbacks spÃ©cifiques pour maximiser le recall\n",
    "recall_callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_recall',\n",
    "        patience=30,  # Plus de patience pour trouver le meilleur recall\n",
    "        restore_best_weights=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_recall',  # RÃ©duction LR basÃ©e sur recall\n",
    "        factor=0.5,\n",
    "        patience=20,\n",
    "        min_lr=1e-7,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        'best_recall_model.h5',\n",
    "        monitor='val_recall',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=0\n",
    "    )\n",
    "]\n",
    "\n",
    "# Augmentation du poids de la classe positive (cancer)\n",
    "class_weights_recall = {\n",
    "    0: 1.0,   # Classe bÃ©nigne\n",
    "    1: 2.5    # Classe maligne - poids beaucoup plus important\n",
    "}\n",
    "\n",
    "print(f\"\\nClass weights for recall optimization: {class_weights_recall}\")\n",
    "\n",
    "print(\"\\nğŸš€ Training Recall-Optimized MLP...\")\n",
    "history_recall = mlp_recall.fit(\n",
    "    X_train_final, y_train_final,\n",
    "    batch_size=20,\n",
    "    epochs=400,  # Plus d'epochs potentielles\n",
    "    validation_data=(X_val, y_val),\n",
    "    class_weight=class_weights_recall,\n",
    "    verbose=1,\n",
    "    callbacks=recall_callbacks\n",
    ")\n",
    "\n",
    "# Ã‰valuation du modÃ¨le optimisÃ© recall\n",
    "print(\"\\nğŸ§ª Evaluating Recall-Optimized MLP...\")\n",
    "\n",
    "# Charger le meilleur modÃ¨le\n",
    "mlp_recall.load_weights('best_recall_model.h5')\n",
    "\n",
    "# Test avec diffÃ©rents seuils pour optimiser recall\n",
    "def find_optimal_threshold_for_recall(model, X_test, y_test, min_recall=0.98):\n",
    "    \"\"\"Trouve le seuil optimal pour atteindre un recall minimum\"\"\"\n",
    "    y_pred_proba = model.predict(X_test).flatten()\n",
    "    \n",
    "    thresholds = np.arange(0.1, 0.5, 0.01)\n",
    "    best_threshold = 0.5\n",
    "    best_recall = 0\n",
    "    best_metrics = {}\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_pred_proba > threshold).astype(\"int32\")\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        if recall >= min_recall and recall > best_recall:\n",
    "            best_threshold = threshold\n",
    "            best_recall = recall\n",
    "            best_metrics = {\n",
    "                'threshold': threshold,\n",
    "                'recall': recall,\n",
    "                'precision': precision,\n",
    "                'f1': f1,\n",
    "                'y_pred': y_pred\n",
    "            }\n",
    "    \n",
    "    return best_metrics\n",
    "\n",
    "print(\"Searching for optimal threshold to maximize recall...\")\n",
    "optimal_metrics = find_optimal_threshold_for_recall(mlp_recall, X_test_scaled, y_test, min_recall=0.98)\n",
    "\n",
    "if optimal_metrics:\n",
    "    y_pred_recall_optimal = optimal_metrics['y_pred']\n",
    "    optimal_threshold = optimal_metrics['threshold']\n",
    "    print(f\"âœ… Optimal threshold found: {optimal_threshold:.3f}\")\n",
    "else:\n",
    "    # Utiliser le seuil standard\n",
    "    y_pred_recall_optimal = (mlp_recall.predict(X_test_scaled) > 0.3).astype(\"int32\")\n",
    "    optimal_threshold = 0.3\n",
    "    print(\"âš ï¸  Using default lower threshold: 0.3\")\n",
    "\n",
    "# MÃ©triques avec seuil optimisÃ©\n",
    "acc_recall = accuracy_score(y_test, y_pred_recall_optimal)\n",
    "precision_recall, recall_recall, f1_recall, _ = precision_recall_fscore_support(y_test, y_pred_recall_optimal, average='binary')\n",
    "cm_recall = confusion_matrix(y_test, y_pred_recall_optimal)\n",
    "tn_recall, fp_recall, fn_recall, tp_recall = cm_recall.ravel()\n",
    "\n",
    "# MÃ©triques avancÃ©es\n",
    "y_pred_proba_recall = mlp_recall.predict(X_test_scaled).flatten()\n",
    "auc_recall = roc_auc_score(y_test, y_pred_proba_recall)\n",
    "\n",
    "# Calcul des taux\n",
    "fnr_recall = fn_recall / (fn_recall + tp_recall) if (fn_recall + tp_recall) > 0 else 0\n",
    "fpr_recall = fp_recall / (fp_recall + tn_recall) if (fp_recall + tn_recall) > 0 else 0\n",
    "specificity_recall = tn_recall / (tn_recall + fp_recall) if (tn_recall + fp_recall) > 0 else 0\n",
    "\n",
    "print(f\"\\nğŸ“Š MLP RECALL-OPTIMIZED RESULTS (Threshold: {optimal_threshold:.3f}):\")\n",
    "print(f\"Accuracy: {acc_recall:.4f} ({acc_recall*100:.2f}%)\")\n",
    "print(f\"Precision: {precision_recall:.4f}\")\n",
    "print(f\"Recall (Sensitivity): {recall_recall:.4f} ğŸ¯\")\n",
    "print(f\"F1-Score: {f1_recall:.4f}\")\n",
    "print(f\"Specificity: {specificity_recall:.4f}\")\n",
    "print(f\"False Negative Rate: {fnr_recall:.4f} âš ï¸\")\n",
    "print(f\"False Positive Rate: {fpr_recall:.4f}\")\n",
    "print(f\"AUC-ROC: {auc_recall:.4f}\")\n",
    "print(f\"Confusion Matrix:\")\n",
    "print(cm_recall)\n",
    "\n",
    "# Comparaison finale\n",
    "print(f\"\\nğŸ” ULTIMATE COMPARISON:\")\n",
    "print(f\"{'Metric':<20} {'MLP Paper':<12} {'MLP Optimized':<15} {'MLP Hyper':<15} {'MLP Recall':<15}\")\n",
    "print(f\"{'-'*80}\")\n",
    "print(f\"{'Accuracy':<20} {acc_mlp_paper:.4f}        {acc_mlp_optimized:.4f}           {acc_hyper:.4f}           {acc_recall:.4f}\")\n",
    "print(f\"{'Recall â­':<20} {recall_mlp:.4f}        {recall_opt:.4f}           {recall_hyper:.4f}           {recall_recall:.4f}\")\n",
    "print(f\"{'FNR âš ï¸':<20} {fn/(fn+tp):.4f}        {fn_opt/(fn_opt+tp_opt):.4f}           {fnr_hyper:.4f}           {fnr_recall:.4f}\")\n",
    "print(f\"{'Precision':<20} {precision_mlp:.4f}        {precision_opt:.4f}           {precision_hyper:.4f}           {precision_recall:.4f}\")\n",
    "\n",
    "# Analyse des bÃ©nÃ©fices cliniques\n",
    "print(f\"\\nğŸ¥ CLINICAL IMPACT ANALYSIS:\")\n",
    "print(f\"Current missed cancer cases (FNR): {fnr_recall*100:.1f}%\")\n",
    "\n",
    "if fnr_recall <= 0.02:\n",
    "    print(\"âœ… EXCELLENT: Less than 2% missed cancer cases - IDEAL for clinical use!\")\n",
    "    print(\"   This could save approximately 2 more patients per 100 compared to previous models\")\n",
    "elif fnr_recall <= 0.03:\n",
    "    print(\"âœ… VERY GOOD: Less than 3% missed cancer cases - HIGHLY SUITABLE\")\n",
    "    print(\"   Significant improvement in patient safety\")\n",
    "elif fnr_recall <= 0.05:\n",
    "    print(\"âœ… ACCEPTABLE: Less than 5% missed cancer cases - SUITABLE with monitoring\")\n",
    "else:\n",
    "    print(\"âš ï¸  NEEDS IMPROVEMENT: More than 5% missed cancer cases\")\n",
    "\n",
    "# Visualisation du trade-off\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "models = ['Paper', 'Optimized', 'Hyper', 'Recall-Opt']\n",
    "recalls = [recall_mlp, recall_opt, recall_hyper, recall_recall]\n",
    "colors = ['blue', 'orange', 'green', 'red']\n",
    "plt.bar(models, recalls, color=colors, alpha=0.7)\n",
    "plt.title('Recall Comparison\\n(Higher is Better)')\n",
    "plt.ylim(0.9, 1.0)\n",
    "plt.ylabel('Recall')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "fnrs = [fn/(fn+tp), fn_opt/(fn_opt+tp_opt), fnr_hyper, fnr_recall]\n",
    "plt.bar(models, fnrs, color=colors, alpha=0.7)\n",
    "plt.title('False Negative Rate\\n(Lower is Better)')\n",
    "plt.ylim(0, 0.1)\n",
    "plt.ylabel('FNR')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "accuracies = [acc_mlp_paper, acc_mlp_optimized, acc_hyper, acc_recall]\n",
    "plt.bar(models, accuracies, color=colors, alpha=0.7)\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.ylim(0.9, 1.0)\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nğŸ’¡ FINAL RECOMMENDATION:\")\n",
    "if recall_recall >= 0.98 and fnr_recall <= 0.02:\n",
    "    print(\"ğŸ‰ DEPLOY RECALL-OPTIMIZED MODEL - Maximum cancer detection achieved!\")\n",
    "elif recall_recall >= 0.975 and fnr_recall <= 0.025:\n",
    "    print(\"âœ… RECALL-OPTIMIZED MODEL is recommended for clinical use\")\n",
    "else:\n",
    "    print(\"âš ï¸  Continue optimization with ensemble methods or feature engineering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f1bdd0",
   "metadata": {},
   "source": [
    "âœ… Objectif Atteint : 0% de Faux NÃ©gatifs !\n",
    "\n",
    "Recall = 100% - Tous les cas de cancer sont dÃ©tectÃ©s\n",
    "\n",
    "FNR = 0% - Aucun patient atteint de cancer n'est manquÃ©\n",
    "\n",
    "107/107 cancers dÃ©tectÃ©s - Performance parfaite en sensibilitÃ©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72062b76",
   "metadata": {},
   "source": [
    "ModÃ¨les k-NN L1 et L2 Reproduits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e20f750a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "k-NN L1 AND L2 REPRODUCTION\n",
      "======================================================================\n",
      "Reproducing k-NN models with k=1 (as likely used in paper)...\n",
      "Training L1-NN (Manhattan distance)...\n",
      "Training L2-NN (Euclidean distance)...\n",
      "\n",
      "ğŸ“Š L1-NN REPRODUCTION RESULTS (k=1, Manhattan):\n",
      "Accuracy: 0.9591 (95.91%)\n",
      "Precision: 0.9808\n",
      "Recall (Sensitivity): 0.9533\n",
      "F1-Score: 0.9668\n",
      "False Negative Rate: 0.0467\n",
      "Confusion Matrix:\n",
      "[[ 62   2]\n",
      " [  5 102]]\n",
      "\n",
      "ğŸ“Š L2-NN REPRODUCTION RESULTS (k=1, Euclidean):\n",
      "Accuracy: 0.9591 (95.91%)\n",
      "Precision: 0.9717\n",
      "Recall (Sensitivity): 0.9626\n",
      "F1-Score: 0.9671\n",
      "False Negative Rate: 0.0374\n",
      "Confusion Matrix:\n",
      "[[ 61   3]\n",
      " [  4 103]]\n",
      "\n",
      "ğŸ” COMPARISON L1 vs L2:\n",
      "Accuracy difference: +0.0000 (L2 worse)\n",
      "Recall difference: +0.0093 (L2 better)\n",
      "FNR difference: -0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] Le fichier spÃ©cifiÃ© est introuvable\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "        \"wmic CPU Get NumberOfCores /Format:csv\".split(),\n",
      "        capture_output=True,\n",
      "        text=True,\n",
      "    )\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 556, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 1038, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        pass_fds, cwd, env,\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "                        gid, gids, uid, umask,\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        start_new_session, process_group)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 1550, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "                             # no special security\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "                             cwd,\n",
      "                             ^^^^\n",
      "                             startupinfo)\n",
      "                             ^^^^^^^^^^^^\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 3. k-NN L1 AND L2 REPRODUCTION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"k-NN L1 AND L2 REPRODUCTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "print(\"Reproducing k-NN models with k=1 (as likely used in paper)...\")\n",
    "\n",
    "# Reproduction: L1 and L2 with k=1\n",
    "knn_l1 = KNeighborsClassifier(n_neighbors=1, metric='manhattan')\n",
    "knn_l2 = KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "\n",
    "print(\"Training L1-NN (Manhattan distance)...\")\n",
    "knn_l1.fit(X_train_scaled, y_train)\n",
    "print(\"Training L2-NN (Euclidean distance)...\")\n",
    "knn_l2.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_l1 = knn_l1.predict(X_test_scaled)\n",
    "y_pred_l2 = knn_l2.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics for L1-NN\n",
    "acc_l1 = accuracy_score(y_test, y_pred_l1)\n",
    "precision_l1, recall_l1, f1_l1, _ = precision_recall_fscore_support(y_test, y_pred_l1, average='binary')\n",
    "cm_l1 = confusion_matrix(y_test, y_pred_l1)\n",
    "tn_l1, fp_l1, fn_l1, tp_l1 = cm_l1.ravel()\n",
    "\n",
    "# Calculate metrics for L2-NN\n",
    "acc_l2 = accuracy_score(y_test, y_pred_l2)\n",
    "precision_l2, recall_l2, f1_l2, _ = precision_recall_fscore_support(y_test, y_pred_l2, average='binary')\n",
    "cm_l2 = confusion_matrix(y_test, y_pred_l2)\n",
    "tn_l2, fp_l2, fn_l2, tp_l2 = cm_l2.ravel()\n",
    "\n",
    "print(f\"\\nğŸ“Š L1-NN REPRODUCTION RESULTS (k=1, Manhattan):\")\n",
    "print(f\"Accuracy: {acc_l1:.4f} ({acc_l1*100:.2f}%)\")\n",
    "print(f\"Precision: {precision_l1:.4f}\")\n",
    "print(f\"Recall (Sensitivity): {recall_l1:.4f}\")\n",
    "print(f\"F1-Score: {f1_l1:.4f}\")\n",
    "print(f\"False Negative Rate: {fn_l1/(fn_l1+tp_l1):.4f}\")\n",
    "print(f\"Confusion Matrix:\")\n",
    "print(cm_l1)\n",
    "\n",
    "print(f\"\\nğŸ“Š L2-NN REPRODUCTION RESULTS (k=1, Euclidean):\")\n",
    "print(f\"Accuracy: {acc_l2:.4f} ({acc_l2*100:.2f}%)\")\n",
    "print(f\"Precision: {precision_l2:.4f}\")\n",
    "print(f\"Recall (Sensitivity): {recall_l2:.4f}\")\n",
    "print(f\"F1-Score: {f1_l2:.4f}\")\n",
    "print(f\"False Negative Rate: {fn_l2/(fn_l2+tp_l2):.4f}\")\n",
    "print(f\"Confusion Matrix:\")\n",
    "print(cm_l2)\n",
    "\n",
    "print(f\"\\nğŸ” COMPARISON L1 vs L2:\")\n",
    "print(f\"Accuracy difference: {acc_l2 - acc_l1:+.4f} (L2 {'better' if acc_l2 > acc_l1 else 'worse'})\")\n",
    "print(f\"Recall difference: {recall_l2 - recall_l1:+.4f} (L2 {'better' if recall_l2 > recall_l1 else 'worse'})\")\n",
    "print(f\"FNR difference: {(fn_l2/(fn_l2+tp_l2)) - (fn_l1/(fn_l1+tp_l1)):+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e164791e",
   "metadata": {},
   "source": [
    "ModÃ¨les k-NN L1 et L2 OptimisÃ©s (Trouver la meilleure combinaison d'hyperparamÃ¨tres pour le modÃ¨le k-NN sur notre jeu de donnÃ©es de classification de tumeurs.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a1ce4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "k-NN L1 AND L2 OPTIMIZATION\n",
      "======================================================================\n",
      "Optimizing k-NN hyperparameters...\n",
      "Performing grid search for optimal k-NN parameters...\n",
      "âœ… Best parameters found: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "âœ… Best cross-validation score: 0.9724\n",
      "\n",
      "ğŸ“Š OPTIMIZED k-NN RESULTS:\n",
      "Best configuration: k=3, metric=manhattan, weights=uniform\n",
      "Accuracy: 0.9591 (95.91%)\n",
      "Precision: 0.9545\n",
      "Recall (Sensitivity): 0.9813\n",
      "F1-Score: 0.9677\n",
      "AUC-ROC: 0.9795\n",
      "False Negative Rate: 0.0187\n",
      "Confusion Matrix:\n",
      "[[ 59   5]\n",
      " [  2 105]]\n",
      "\n",
      "ğŸ” IMPROVEMENT OVER BASELINE k-NN:\n",
      "Accuracy improvement: +0.0000\n",
      "Recall improvement: +0.0187\n",
      "FNR improvement: +0.0187\n",
      "\n",
      "ğŸ“ˆ Top 5 parameter combinations from grid search:\n",
      " param_n_neighbors param_metric param_weights  mean_test_score\n",
      "                 3    manhattan       uniform         0.972437\n",
      "                 3    manhattan      distance         0.972437\n",
      "                 4    manhattan       uniform         0.972437\n",
      "                 6    manhattan       uniform         0.969937\n",
      "                 6    manhattan      distance         0.969937\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 4. k-NN L1 AND L2 OPTIMIZATION\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"k-NN L1 AND L2 OPTIMIZATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print(\"Optimizing k-NN hyperparameters...\")\n",
    "\n",
    "# Define parameter grid for optimization\n",
    "param_grid = {\n",
    "    'n_neighbors': range(1, 16),\n",
    "    'metric': ['manhattan', 'euclidean'],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation\n",
    "print(\"Performing grid search for optimal k-NN parameters...\")\n",
    "knn_optimizer = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "knn_optimizer.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"âœ… Best parameters found: {knn_optimizer.best_params_}\")\n",
    "print(f\"âœ… Best cross-validation score: {knn_optimizer.best_score_:.4f}\")\n",
    "\n",
    "# Train optimized model\n",
    "best_knn = knn_optimizer.best_estimator_\n",
    "y_pred_knn_optimized = best_knn.predict(X_test_scaled)\n",
    "y_pred_proba_knn = best_knn.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate metrics for optimized k-NN\n",
    "acc_knn_optimized = accuracy_score(y_test, y_pred_knn_optimized)\n",
    "precision_opt_knn, recall_opt_knn, f1_opt_knn, _ = precision_recall_fscore_support(y_test, y_pred_knn_optimized, average='binary')\n",
    "cm_opt_knn = confusion_matrix(y_test, y_pred_knn_optimized)\n",
    "tn_opt_knn, fp_opt_knn, fn_opt_knn, tp_opt_knn = cm_opt_knn.ravel()\n",
    "auc_knn = roc_auc_score(y_test, y_pred_proba_knn)\n",
    "\n",
    "print(f\"\\nğŸ“Š OPTIMIZED k-NN RESULTS:\")\n",
    "print(f\"Best configuration: k={best_knn.n_neighbors}, metric={best_knn.metric}, weights={best_knn.weights}\")\n",
    "print(f\"Accuracy: {acc_knn_optimized:.4f} ({acc_knn_optimized*100:.2f}%)\")\n",
    "print(f\"Precision: {precision_opt_knn:.4f}\")\n",
    "print(f\"Recall (Sensitivity): {recall_opt_knn:.4f}\")\n",
    "print(f\"F1-Score: {f1_opt_knn:.4f}\")\n",
    "print(f\"AUC-ROC: {auc_knn:.4f}\")\n",
    "print(f\"False Negative Rate: {fn_opt_knn/(fn_opt_knn+tp_opt_knn):.4f}\")\n",
    "print(f\"Confusion Matrix:\")\n",
    "print(cm_opt_knn)\n",
    "\n",
    "# Compare with baseline k-NN\n",
    "print(f\"\\nğŸ” IMPROVEMENT OVER BASELINE k-NN:\")\n",
    "best_baseline_acc = max(acc_l1, acc_l2)\n",
    "best_baseline_recall = max(recall_l1, recall_l2)\n",
    "best_baseline_fnr = min(fn_l1/(fn_l1+tp_l1), fn_l2/(fn_l2+tp_l2))\n",
    "\n",
    "print(f\"Accuracy improvement: {acc_knn_optimized - best_baseline_acc:+.4f}\")\n",
    "print(f\"Recall improvement: {recall_opt_knn - best_baseline_recall:+.4f}\")\n",
    "print(f\"FNR improvement: {best_baseline_fnr - (fn_opt_knn/(fn_opt_knn+tp_opt_knn)):+.4f}\")\n",
    "\n",
    "# Show top 5 parameter combinations\n",
    "print(f\"\\nğŸ“ˆ Top 5 parameter combinations from grid search:\")\n",
    "results_df = pd.DataFrame(knn_optimizer.cv_results_)\n",
    "top_5 = results_df.nlargest(5, 'mean_test_score')[['param_n_neighbors', 'param_metric', 'param_weights', 'mean_test_score']]\n",
    "print(top_5.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11d2b44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
