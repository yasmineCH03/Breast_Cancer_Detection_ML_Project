{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b24d8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf157900",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "612019ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DATASET INFORMATION\n",
      "======================================================================\n",
      "Total samples: 569\n",
      "Number of features: 30\n",
      "Malignant cases (0): 212\n",
      "Benign cases (1): 357\n",
      "\n",
      "Feature names: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness']... (showing first 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATASET INFORMATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total samples: {X.shape[0]}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(f\"Malignant cases (0): {np.sum(y == 0)}\")\n",
    "print(f\"Benign cases (1): {np.sum(y == 1)}\")\n",
    "print(f\"\\nFeature names: {data.feature_names[:5]}... (showing first 5)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "517740eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X, columns=data.feature_names)\n",
    "df['target'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ad0c7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows of the dataset:\n",
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "2           0.15990          0.1974              0.12790         0.2069   \n",
      "3           0.28390          0.2414              0.10520         0.2597   \n",
      "4           0.13280          0.1980              0.10430         0.1809   \n",
      "\n",
      "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
      "0                 0.07871  ...          17.33           184.60      2019.0   \n",
      "1                 0.05667  ...          23.41           158.80      1956.0   \n",
      "2                 0.05999  ...          25.53           152.50      1709.0   \n",
      "3                 0.09744  ...          26.50            98.87       567.7   \n",
      "4                 0.05883  ...          16.67           152.20      1575.0   \n",
      "\n",
      "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
      "0            0.1622             0.6656           0.7119                0.2654   \n",
      "1            0.1238             0.1866           0.2416                0.1860   \n",
      "2            0.1444             0.4245           0.4504                0.2430   \n",
      "3            0.2098             0.8663           0.6869                0.2575   \n",
      "4            0.1374             0.2050           0.4000                0.1625   \n",
      "\n",
      "   worst symmetry  worst fractal dimension  target  \n",
      "0          0.4601                  0.11890       0  \n",
      "1          0.2750                  0.08902       0  \n",
      "2          0.3613                  0.08758       0  \n",
      "3          0.6638                  0.17300       0  \n",
      "4          0.2364                  0.07678       0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "Dataset statistics:\n",
      "       mean radius  mean texture  mean perimeter    mean area  \\\n",
      "count   569.000000    569.000000      569.000000   569.000000   \n",
      "mean     14.127292     19.289649       91.969033   654.889104   \n",
      "std       3.524049      4.301036       24.298981   351.914129   \n",
      "min       6.981000      9.710000       43.790000   143.500000   \n",
      "25%      11.700000     16.170000       75.170000   420.300000   \n",
      "50%      13.370000     18.840000       86.240000   551.100000   \n",
      "75%      15.780000     21.800000      104.100000   782.700000   \n",
      "max      28.110000     39.280000      188.500000  2501.000000   \n",
      "\n",
      "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
      "count       569.000000        569.000000      569.000000           569.000000   \n",
      "mean          0.096360          0.104341        0.088799             0.048919   \n",
      "std           0.014064          0.052813        0.079720             0.038803   \n",
      "min           0.052630          0.019380        0.000000             0.000000   \n",
      "25%           0.086370          0.064920        0.029560             0.020310   \n",
      "50%           0.095870          0.092630        0.061540             0.033500   \n",
      "75%           0.105300          0.130400        0.130700             0.074000   \n",
      "max           0.163400          0.345400        0.426800             0.201200   \n",
      "\n",
      "       mean symmetry  mean fractal dimension  ...  worst texture  \\\n",
      "count     569.000000              569.000000  ...     569.000000   \n",
      "mean        0.181162                0.062798  ...      25.677223   \n",
      "std         0.027414                0.007060  ...       6.146258   \n",
      "min         0.106000                0.049960  ...      12.020000   \n",
      "25%         0.161900                0.057700  ...      21.080000   \n",
      "50%         0.179200                0.061540  ...      25.410000   \n",
      "75%         0.195700                0.066120  ...      29.720000   \n",
      "max         0.304000                0.097440  ...      49.540000   \n",
      "\n",
      "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
      "count       569.000000   569.000000        569.000000         569.000000   \n",
      "mean        107.261213   880.583128          0.132369           0.254265   \n",
      "std          33.602542   569.356993          0.022832           0.157336   \n",
      "min          50.410000   185.200000          0.071170           0.027290   \n",
      "25%          84.110000   515.300000          0.116600           0.147200   \n",
      "50%          97.660000   686.500000          0.131300           0.211900   \n",
      "75%         125.400000  1084.000000          0.146000           0.339100   \n",
      "max         251.200000  4254.000000          0.222600           1.058000   \n",
      "\n",
      "       worst concavity  worst concave points  worst symmetry  \\\n",
      "count       569.000000            569.000000      569.000000   \n",
      "mean          0.272188              0.114606        0.290076   \n",
      "std           0.208624              0.065732        0.061867   \n",
      "min           0.000000              0.000000        0.156500   \n",
      "25%           0.114500              0.064930        0.250400   \n",
      "50%           0.226700              0.099930        0.282200   \n",
      "75%           0.382900              0.161400        0.317900   \n",
      "max           1.252000              0.291000        0.663800   \n",
      "\n",
      "       worst fractal dimension      target  \n",
      "count               569.000000  569.000000  \n",
      "mean                  0.083946    0.627417  \n",
      "std                   0.018061    0.483918  \n",
      "min                   0.055040    0.000000  \n",
      "25%                   0.071460    0.000000  \n",
      "50%                   0.080040    1.000000  \n",
      "75%                   0.092080    1.000000  \n",
      "max                   0.207500    1.000000  \n",
      "\n",
      "[8 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nDataset statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0889fcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 398 samples\n",
      "Testing set size: 171 samples\n"
     ]
    }
   ],
   "source": [
    "# Split data: 70% training, 30% testing (as per the paper)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Apply Standardization: X' = (X - μ) / σ\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "393b5657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standardization applied!\n",
      "Training data mean (after scaling): [-4.97480337e-15  2.74863884e-15  2.03912822e-15]\n",
      "Training data std (after scaling): [1. 1. 1.]\n",
      "(Showing first 3 features - all should be ~0 mean and ~1 std)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStandardization applied!\")\n",
    "print(f\"Training data mean (after scaling): {np.mean(X_train_scaled, axis=0)[:3]}\")\n",
    "print(f\"Training data std (after scaling): {np.std(X_train_scaled, axis=0)[:3]}\")\n",
    "print(\"(Showing first 3 features - all should be ~0 mean and ~1 std)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c114aa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training KNN model...\n",
      "\n",
      "KNN Results:\n",
      "Training time: 0.0328 seconds\n",
      "Training accuracy: 100.00%\n",
      "Testing accuracy: 95.91%\n",
      "Expected test accuracy (from paper): 95.90%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 61   3]\n",
      " [  4 103]]\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Malignant       0.94      0.95      0.95        64\n",
      "      Benign       0.97      0.96      0.97       107\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.96      0.96      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n",
      "\n",
      "Additional Metrics:\n",
      "Sensitivity (TPR): 96.26%\n",
      "Specificity (TNR): 95.31%\n",
      "False Positive Rate (FPR): 4.69%\n",
      "False Negative Rate (FNR): 3.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] Le fichier spécifié est introuvable\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "        \"wmic CPU Get NumberOfCores /Format:csv\".split(),\n",
      "        capture_output=True,\n",
      "        text=True,\n",
      "    )\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\subprocess.py\", line 554, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\subprocess.py\", line 1039, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        pass_fds, cwd, env,\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "                        gid, gids, uid, umask,\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        start_new_session, process_group)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\anaconda3\\Lib\\subprocess.py\", line 1554, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "                             # no special security\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "                             cwd,\n",
      "                             ^^^^\n",
      "                             startupinfo)\n",
      "                             ^^^^^^^^^^^^\n"
     ]
    }
   ],
   "source": [
    "# Initialize KNN classifier with k=1 (nearest neighbor)\n",
    "knn_model = KNeighborsClassifier(\n",
    "    n_neighbors=1,\n",
    "    metric='euclidean',  # L2 norm: d_L2(p,q) = √(Σ(p_i - q_i)²)\n",
    "    algorithm='auto'\n",
    ")\n",
    "\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_knn = knn_model.predict(X_train_scaled)\n",
    "y_test_pred_knn = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracies\n",
    "knn_train_acc = accuracy_score(y_train, y_train_pred_knn)\n",
    "knn_test_acc = accuracy_score(y_test, y_test_pred_knn)\n",
    "\n",
    "print(f\"\\nKNN Results:\")\n",
    "print(f\"Training accuracy: {knn_train_acc*100:.2f}%\")\n",
    "print(f\"Testing accuracy: {knn_test_acc*100:.2f}%\")\n",
    "print(f\"Expected test accuracy (from paper): 95.90%\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_knn = confusion_matrix(y_test, y_test_pred_knn)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(cm_knn)\n",
    "\n",
    "# Classification Report\n",
    "print(f\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred_knn, \n",
    "                          target_names=['Malignant', 'Benign']))\n",
    "\n",
    "# Calculate additional metrics\n",
    "tn, fp, fn, tp = cm_knn.ravel()\n",
    "sensitivity = tp / (tp + fn)  # TPR (True Positive Rate)\n",
    "specificity = tn / (tn + fp)  # TNR (True Negative Rate)\n",
    "fpr = fp / (fp + tn)  # False Positive Rate\n",
    "fnr = fn / (fn + tp)  # False Negative Rate\n",
    "\n",
    "print(f\"\\nAdditional Metrics:\")\n",
    "print(f\"Sensitivity (TPR): {sensitivity*100:.2f}%\")\n",
    "print(f\"Specificity (TNR): {specificity*100:.2f}%\")\n",
    "print(f\"False Positive Rate (FPR): {fpr*100:.2f}%\")\n",
    "print(f\"False Negative Rate (FNR): {fnr*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186e5dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 2: MULTILAYER PERCEPTRON (MLP)\n",
      "======================================================================\n",
      "\n",
      "Building MLP architecture: 500-500-500\n",
      "Activation function: ReLU\n",
      "Loss function: Cross Entropy\n",
      "Optimizer: SGD (Stochastic Gradient Descent)\n",
      "\n",
      "Model Architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">15,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">250,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">250,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,002</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden_layer_1 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │        \u001b[38;5;34m15,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden_layer_2 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │       \u001b[38;5;34m250,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hidden_layer_3 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │       \u001b[38;5;34m250,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │         \u001b[38;5;34m1,002\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">517,502</span> (1.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m517,502\u001b[0m (1.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">517,502</span> (1.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m517,502\u001b[0m (1.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MLP model...\n",
      "Epoch 1/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5288 - loss: 0.6654 - val_accuracy: 0.8500 - val_loss: 0.6130\n",
      "Epoch 2/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8273 - loss: 0.6083 - val_accuracy: 0.9417 - val_loss: 0.5665\n",
      "Epoch 3/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9029 - loss: 0.5639 - val_accuracy: 0.9583 - val_loss: 0.5275\n",
      "Epoch 4/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9317 - loss: 0.5263 - val_accuracy: 0.9667 - val_loss: 0.4946\n",
      "Epoch 5/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9317 - loss: 0.4946 - val_accuracy: 0.9667 - val_loss: 0.4640\n",
      "Epoch 6/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9317 - loss: 0.4652 - val_accuracy: 0.9750 - val_loss: 0.4362\n",
      "Epoch 7/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9245 - loss: 0.4392 - val_accuracy: 0.9750 - val_loss: 0.4117\n",
      "Epoch 8/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9245 - loss: 0.4163 - val_accuracy: 0.9750 - val_loss: 0.3903\n",
      "Epoch 9/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9245 - loss: 0.3960 - val_accuracy: 0.9750 - val_loss: 0.3693\n",
      "Epoch 10/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9245 - loss: 0.3765 - val_accuracy: 0.9750 - val_loss: 0.3505\n",
      "Epoch 11/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9281 - loss: 0.3590 - val_accuracy: 0.9750 - val_loss: 0.3342\n",
      "Epoch 12/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9281 - loss: 0.3435 - val_accuracy: 0.9750 - val_loss: 0.3187\n",
      "Epoch 13/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9317 - loss: 0.3291 - val_accuracy: 0.9750 - val_loss: 0.3036\n",
      "Epoch 14/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9317 - loss: 0.3154 - val_accuracy: 0.9750 - val_loss: 0.2898\n",
      "Epoch 15/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9317 - loss: 0.3030 - val_accuracy: 0.9750 - val_loss: 0.2779\n",
      "Epoch 16/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9317 - loss: 0.2920 - val_accuracy: 0.9833 - val_loss: 0.2668\n",
      "Epoch 17/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9317 - loss: 0.2820 - val_accuracy: 0.9833 - val_loss: 0.2565\n",
      "Epoch 18/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9317 - loss: 0.2728 - val_accuracy: 0.9833 - val_loss: 0.2468\n",
      "Epoch 19/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9353 - loss: 0.2640 - val_accuracy: 0.9833 - val_loss: 0.2381\n",
      "Epoch 20/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9353 - loss: 0.2561 - val_accuracy: 0.9833 - val_loss: 0.2294\n",
      "Epoch 21/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9353 - loss: 0.2483 - val_accuracy: 0.9833 - val_loss: 0.2218\n",
      "Epoch 22/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9424 - loss: 0.2414 - val_accuracy: 0.9833 - val_loss: 0.2146\n",
      "Epoch 23/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9424 - loss: 0.2350 - val_accuracy: 0.9833 - val_loss: 0.2080\n",
      "Epoch 24/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9424 - loss: 0.2291 - val_accuracy: 0.9833 - val_loss: 0.2021\n",
      "Epoch 25/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9424 - loss: 0.2235 - val_accuracy: 0.9750 - val_loss: 0.1962\n",
      "Epoch 26/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9424 - loss: 0.2181 - val_accuracy: 0.9750 - val_loss: 0.1904\n",
      "Epoch 27/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9424 - loss: 0.2127 - val_accuracy: 0.9750 - val_loss: 0.1849\n",
      "Epoch 28/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9496 - loss: 0.2077 - val_accuracy: 0.9750 - val_loss: 0.1798\n",
      "Epoch 29/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9496 - loss: 0.2032 - val_accuracy: 0.9750 - val_loss: 0.1752\n",
      "Epoch 30/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9496 - loss: 0.1991 - val_accuracy: 0.9750 - val_loss: 0.1708\n",
      "Epoch 31/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9496 - loss: 0.1950 - val_accuracy: 0.9750 - val_loss: 0.1666\n",
      "Epoch 32/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9496 - loss: 0.1912 - val_accuracy: 0.9750 - val_loss: 0.1624\n",
      "Epoch 33/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9496 - loss: 0.1873 - val_accuracy: 0.9750 - val_loss: 0.1584\n",
      "Epoch 34/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9496 - loss: 0.1838 - val_accuracy: 0.9750 - val_loss: 0.1552\n",
      "Epoch 35/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9532 - loss: 0.1806 - val_accuracy: 0.9750 - val_loss: 0.1524\n",
      "Epoch 36/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9532 - loss: 0.1777 - val_accuracy: 0.9750 - val_loss: 0.1490\n",
      "Epoch 37/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9532 - loss: 0.1746 - val_accuracy: 0.9750 - val_loss: 0.1456\n",
      "Epoch 38/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9532 - loss: 0.1715 - val_accuracy: 0.9750 - val_loss: 0.1424\n",
      "Epoch 39/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9568 - loss: 0.1686 - val_accuracy: 0.9750 - val_loss: 0.1395\n",
      "Epoch 40/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9604 - loss: 0.1658 - val_accuracy: 0.9750 - val_loss: 0.1370\n",
      "Epoch 41/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9604 - loss: 0.1632 - val_accuracy: 0.9750 - val_loss: 0.1344\n",
      "Epoch 42/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9604 - loss: 0.1609 - val_accuracy: 0.9833 - val_loss: 0.1318\n",
      "Epoch 43/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9604 - loss: 0.1584 - val_accuracy: 0.9833 - val_loss: 0.1295\n",
      "Epoch 44/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9604 - loss: 0.1562 - val_accuracy: 0.9833 - val_loss: 0.1271\n",
      "Epoch 45/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9604 - loss: 0.1539 - val_accuracy: 0.9833 - val_loss: 0.1249\n",
      "Epoch 46/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9604 - loss: 0.1519 - val_accuracy: 0.9833 - val_loss: 0.1228\n",
      "Epoch 47/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9604 - loss: 0.1499 - val_accuracy: 0.9833 - val_loss: 0.1207\n",
      "Epoch 48/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9604 - loss: 0.1478 - val_accuracy: 0.9833 - val_loss: 0.1189\n",
      "Epoch 49/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9604 - loss: 0.1460 - val_accuracy: 0.9833 - val_loss: 0.1169\n",
      "Epoch 50/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9604 - loss: 0.1442 - val_accuracy: 0.9833 - val_loss: 0.1152\n",
      "Epoch 51/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9604 - loss: 0.1425 - val_accuracy: 0.9833 - val_loss: 0.1138\n",
      "Epoch 52/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9640 - loss: 0.1408 - val_accuracy: 0.9833 - val_loss: 0.1121\n",
      "Epoch 53/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9640 - loss: 0.1391 - val_accuracy: 0.9833 - val_loss: 0.1103\n",
      "Epoch 54/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9640 - loss: 0.1373 - val_accuracy: 0.9833 - val_loss: 0.1087\n",
      "Epoch 55/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9640 - loss: 0.1358 - val_accuracy: 0.9833 - val_loss: 0.1070\n",
      "Epoch 56/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9640 - loss: 0.1342 - val_accuracy: 0.9833 - val_loss: 0.1057\n",
      "Epoch 57/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9640 - loss: 0.1327 - val_accuracy: 0.9833 - val_loss: 0.1042\n",
      "Epoch 58/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9640 - loss: 0.1313 - val_accuracy: 0.9833 - val_loss: 0.1027\n",
      "Epoch 59/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9676 - loss: 0.1299 - val_accuracy: 0.9833 - val_loss: 0.1012\n",
      "Epoch 60/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9712 - loss: 0.1284 - val_accuracy: 0.9833 - val_loss: 0.0998\n",
      "Epoch 61/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9712 - loss: 0.1271 - val_accuracy: 0.9833 - val_loss: 0.0982\n",
      "Epoch 62/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9712 - loss: 0.1257 - val_accuracy: 0.9833 - val_loss: 0.0971\n",
      "Epoch 63/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9712 - loss: 0.1242 - val_accuracy: 0.9833 - val_loss: 0.0959\n",
      "Epoch 64/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9712 - loss: 0.1230 - val_accuracy: 0.9833 - val_loss: 0.0945\n",
      "Epoch 65/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9712 - loss: 0.1217 - val_accuracy: 0.9833 - val_loss: 0.0934\n",
      "Epoch 66/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9712 - loss: 0.1206 - val_accuracy: 0.9833 - val_loss: 0.0924\n",
      "Epoch 67/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9712 - loss: 0.1195 - val_accuracy: 0.9833 - val_loss: 0.0917\n",
      "Epoch 68/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9712 - loss: 0.1185 - val_accuracy: 0.9833 - val_loss: 0.0906\n",
      "Epoch 69/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9712 - loss: 0.1174 - val_accuracy: 0.9833 - val_loss: 0.0898\n",
      "Epoch 70/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9712 - loss: 0.1163 - val_accuracy: 0.9833 - val_loss: 0.0888\n",
      "Epoch 71/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9748 - loss: 0.1152 - val_accuracy: 0.9833 - val_loss: 0.0877\n",
      "Epoch 72/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9748 - loss: 0.1141 - val_accuracy: 0.9833 - val_loss: 0.0868\n",
      "Epoch 73/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9748 - loss: 0.1131 - val_accuracy: 0.9833 - val_loss: 0.0859\n",
      "Epoch 74/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9748 - loss: 0.1122 - val_accuracy: 0.9833 - val_loss: 0.0851\n",
      "Epoch 75/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9748 - loss: 0.1112 - val_accuracy: 0.9833 - val_loss: 0.0843\n",
      "Epoch 76/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9748 - loss: 0.1102 - val_accuracy: 0.9833 - val_loss: 0.0834\n",
      "Epoch 77/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9748 - loss: 0.1093 - val_accuracy: 0.9833 - val_loss: 0.0827\n",
      "Epoch 78/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9784 - loss: 0.1084 - val_accuracy: 0.9833 - val_loss: 0.0818\n",
      "Epoch 79/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9784 - loss: 0.1074 - val_accuracy: 0.9833 - val_loss: 0.0809\n",
      "Epoch 80/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9784 - loss: 0.1064 - val_accuracy: 0.9833 - val_loss: 0.0803\n",
      "Epoch 81/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9784 - loss: 0.1058 - val_accuracy: 0.9833 - val_loss: 0.0795\n",
      "Epoch 82/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9784 - loss: 0.1050 - val_accuracy: 0.9833 - val_loss: 0.0789\n",
      "Epoch 83/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9784 - loss: 0.1040 - val_accuracy: 0.9833 - val_loss: 0.0782\n",
      "Epoch 84/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9784 - loss: 0.1032 - val_accuracy: 0.9833 - val_loss: 0.0774\n",
      "Epoch 85/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9784 - loss: 0.1025 - val_accuracy: 0.9833 - val_loss: 0.0769\n",
      "Epoch 86/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9784 - loss: 0.1018 - val_accuracy: 0.9833 - val_loss: 0.0762\n",
      "Epoch 87/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9784 - loss: 0.1012 - val_accuracy: 0.9833 - val_loss: 0.0757\n",
      "Epoch 88/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9820 - loss: 0.1003 - val_accuracy: 0.9833 - val_loss: 0.0751\n",
      "Epoch 89/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9820 - loss: 0.0997 - val_accuracy: 0.9833 - val_loss: 0.0745\n",
      "Epoch 90/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9820 - loss: 0.0991 - val_accuracy: 0.9833 - val_loss: 0.0738\n",
      "Epoch 91/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9820 - loss: 0.0985 - val_accuracy: 0.9833 - val_loss: 0.0733\n",
      "Epoch 92/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9820 - loss: 0.0978 - val_accuracy: 0.9833 - val_loss: 0.0727\n",
      "Epoch 93/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9820 - loss: 0.0971 - val_accuracy: 0.9833 - val_loss: 0.0722\n",
      "Epoch 94/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9820 - loss: 0.0966 - val_accuracy: 0.9833 - val_loss: 0.0716\n",
      "Epoch 95/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9820 - loss: 0.0959 - val_accuracy: 0.9833 - val_loss: 0.0710\n",
      "Epoch 96/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9820 - loss: 0.0953 - val_accuracy: 0.9833 - val_loss: 0.0705\n",
      "Epoch 97/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9820 - loss: 0.0947 - val_accuracy: 0.9833 - val_loss: 0.0699\n",
      "Epoch 98/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9820 - loss: 0.0940 - val_accuracy: 0.9833 - val_loss: 0.0695\n",
      "Epoch 99/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9820 - loss: 0.0932 - val_accuracy: 0.9833 - val_loss: 0.0691\n",
      "Epoch 100/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9820 - loss: 0.0928 - val_accuracy: 0.9833 - val_loss: 0.0686\n",
      "Epoch 101/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9820 - loss: 0.0922 - val_accuracy: 0.9833 - val_loss: 0.0681\n",
      "Epoch 102/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9820 - loss: 0.0917 - val_accuracy: 0.9833 - val_loss: 0.0675\n",
      "Epoch 103/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9820 - loss: 0.0912 - val_accuracy: 0.9833 - val_loss: 0.0672\n",
      "Epoch 104/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9820 - loss: 0.0907 - val_accuracy: 0.9833 - val_loss: 0.0666\n",
      "Epoch 105/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9820 - loss: 0.0901 - val_accuracy: 0.9833 - val_loss: 0.0662\n",
      "Epoch 106/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9820 - loss: 0.0897 - val_accuracy: 0.9833 - val_loss: 0.0657\n",
      "Epoch 107/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9820 - loss: 0.0892 - val_accuracy: 0.9833 - val_loss: 0.0653\n",
      "Epoch 108/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9820 - loss: 0.0887 - val_accuracy: 0.9833 - val_loss: 0.0648\n",
      "Epoch 109/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9820 - loss: 0.0883 - val_accuracy: 0.9833 - val_loss: 0.0644\n",
      "Epoch 110/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9820 - loss: 0.0878 - val_accuracy: 0.9833 - val_loss: 0.0642\n",
      "Epoch 111/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0873 - val_accuracy: 0.9833 - val_loss: 0.0639\n",
      "Epoch 112/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9856 - loss: 0.0868 - val_accuracy: 0.9833 - val_loss: 0.0637\n",
      "Epoch 113/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0863 - val_accuracy: 0.9833 - val_loss: 0.0634\n",
      "Epoch 114/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0859 - val_accuracy: 0.9833 - val_loss: 0.0632\n",
      "Epoch 115/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0853 - val_accuracy: 0.9833 - val_loss: 0.0627\n",
      "Epoch 116/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0849 - val_accuracy: 0.9833 - val_loss: 0.0626\n",
      "Epoch 117/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9856 - loss: 0.0844 - val_accuracy: 0.9833 - val_loss: 0.0623\n",
      "Epoch 118/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0841 - val_accuracy: 0.9833 - val_loss: 0.0619\n",
      "Epoch 119/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0837 - val_accuracy: 0.9833 - val_loss: 0.0615\n",
      "Epoch 120/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0833 - val_accuracy: 0.9833 - val_loss: 0.0612\n",
      "Epoch 121/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0827 - val_accuracy: 0.9833 - val_loss: 0.0610\n",
      "Epoch 122/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0823 - val_accuracy: 0.9833 - val_loss: 0.0606\n",
      "Epoch 123/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0819 - val_accuracy: 0.9833 - val_loss: 0.0601\n",
      "Epoch 124/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9856 - loss: 0.0814 - val_accuracy: 0.9833 - val_loss: 0.0598\n",
      "Epoch 125/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9856 - loss: 0.0810 - val_accuracy: 0.9833 - val_loss: 0.0596\n",
      "Epoch 126/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0806 - val_accuracy: 0.9833 - val_loss: 0.0592\n",
      "Epoch 127/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9856 - loss: 0.0802 - val_accuracy: 0.9833 - val_loss: 0.0588\n",
      "Epoch 128/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0798 - val_accuracy: 0.9833 - val_loss: 0.0588\n",
      "Epoch 129/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0794 - val_accuracy: 0.9833 - val_loss: 0.0585\n",
      "Epoch 130/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0790 - val_accuracy: 0.9833 - val_loss: 0.0582\n",
      "Epoch 131/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0787 - val_accuracy: 0.9833 - val_loss: 0.0580\n",
      "Epoch 132/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0782 - val_accuracy: 0.9833 - val_loss: 0.0579\n",
      "Epoch 133/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0779 - val_accuracy: 0.9833 - val_loss: 0.0575\n",
      "Epoch 134/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0775 - val_accuracy: 0.9833 - val_loss: 0.0571\n",
      "Epoch 135/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9856 - loss: 0.0772 - val_accuracy: 0.9833 - val_loss: 0.0569\n",
      "Epoch 136/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9856 - loss: 0.0768 - val_accuracy: 0.9833 - val_loss: 0.0568\n",
      "Epoch 137/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9856 - loss: 0.0765 - val_accuracy: 0.9833 - val_loss: 0.0564\n",
      "Epoch 138/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0762 - val_accuracy: 0.9833 - val_loss: 0.0561\n",
      "Epoch 139/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9856 - loss: 0.0758 - val_accuracy: 0.9833 - val_loss: 0.0558\n",
      "Epoch 140/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0755 - val_accuracy: 0.9833 - val_loss: 0.0558\n",
      "Epoch 141/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0751 - val_accuracy: 0.9833 - val_loss: 0.0556\n",
      "Epoch 142/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9856 - loss: 0.0749 - val_accuracy: 0.9833 - val_loss: 0.0554\n",
      "Epoch 143/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0744 - val_accuracy: 0.9833 - val_loss: 0.0551\n",
      "Epoch 144/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9856 - loss: 0.0741 - val_accuracy: 0.9833 - val_loss: 0.0552\n",
      "Epoch 145/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9856 - loss: 0.0738 - val_accuracy: 0.9833 - val_loss: 0.0549\n",
      "Epoch 146/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9856 - loss: 0.0736 - val_accuracy: 0.9833 - val_loss: 0.0546\n",
      "Epoch 147/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9856 - loss: 0.0732 - val_accuracy: 0.9833 - val_loss: 0.0544\n",
      "Epoch 148/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9856 - loss: 0.0729 - val_accuracy: 0.9833 - val_loss: 0.0540\n",
      "Epoch 149/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9856 - loss: 0.0726 - val_accuracy: 0.9833 - val_loss: 0.0538\n",
      "Epoch 150/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0723 - val_accuracy: 0.9833 - val_loss: 0.0536\n",
      "Epoch 151/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0721 - val_accuracy: 0.9833 - val_loss: 0.0534\n",
      "Epoch 152/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9856 - loss: 0.0717 - val_accuracy: 0.9833 - val_loss: 0.0533\n",
      "Epoch 153/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0715 - val_accuracy: 0.9833 - val_loss: 0.0529\n",
      "Epoch 154/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0712 - val_accuracy: 0.9833 - val_loss: 0.0527\n",
      "Epoch 155/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0709 - val_accuracy: 0.9833 - val_loss: 0.0529\n",
      "Epoch 156/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0706 - val_accuracy: 0.9833 - val_loss: 0.0528\n",
      "Epoch 157/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9856 - loss: 0.0703 - val_accuracy: 0.9833 - val_loss: 0.0527\n",
      "Epoch 158/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9856 - loss: 0.0699 - val_accuracy: 0.9833 - val_loss: 0.0523\n",
      "Epoch 159/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9856 - loss: 0.0697 - val_accuracy: 0.9833 - val_loss: 0.0521\n",
      "Epoch 160/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9856 - loss: 0.0695 - val_accuracy: 0.9833 - val_loss: 0.0518\n",
      "Epoch 161/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0692 - val_accuracy: 0.9833 - val_loss: 0.0518\n",
      "Epoch 162/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9856 - loss: 0.0689 - val_accuracy: 0.9833 - val_loss: 0.0517\n",
      "Epoch 163/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9856 - loss: 0.0687 - val_accuracy: 0.9833 - val_loss: 0.0518\n",
      "Epoch 164/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0682 - val_accuracy: 0.9833 - val_loss: 0.0517\n",
      "Epoch 165/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9856 - loss: 0.0680 - val_accuracy: 0.9833 - val_loss: 0.0514\n",
      "Epoch 166/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0678 - val_accuracy: 0.9833 - val_loss: 0.0512\n",
      "Epoch 167/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9856 - loss: 0.0676 - val_accuracy: 0.9833 - val_loss: 0.0510\n",
      "Epoch 168/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0673 - val_accuracy: 0.9833 - val_loss: 0.0507\n",
      "Epoch 169/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0671 - val_accuracy: 0.9833 - val_loss: 0.0506\n",
      "Epoch 170/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0668 - val_accuracy: 0.9833 - val_loss: 0.0504\n",
      "Epoch 171/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9856 - loss: 0.0667 - val_accuracy: 0.9833 - val_loss: 0.0502\n",
      "Epoch 172/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9856 - loss: 0.0664 - val_accuracy: 0.9750 - val_loss: 0.0502\n",
      "Epoch 173/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0661 - val_accuracy: 0.9833 - val_loss: 0.0499\n",
      "Epoch 174/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0659 - val_accuracy: 0.9833 - val_loss: 0.0499\n",
      "Epoch 175/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0656 - val_accuracy: 0.9833 - val_loss: 0.0497\n",
      "Epoch 176/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0654 - val_accuracy: 0.9833 - val_loss: 0.0496\n",
      "Epoch 177/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0651 - val_accuracy: 0.9833 - val_loss: 0.0494\n",
      "Epoch 178/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0649 - val_accuracy: 0.9833 - val_loss: 0.0492\n",
      "Epoch 179/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9856 - loss: 0.0647 - val_accuracy: 0.9833 - val_loss: 0.0492\n",
      "Epoch 180/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0644 - val_accuracy: 0.9833 - val_loss: 0.0489\n",
      "Epoch 181/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0642 - val_accuracy: 0.9833 - val_loss: 0.0489\n",
      "Epoch 182/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0640 - val_accuracy: 0.9833 - val_loss: 0.0487\n",
      "Epoch 183/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9856 - loss: 0.0638 - val_accuracy: 0.9833 - val_loss: 0.0485\n",
      "Epoch 184/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9856 - loss: 0.0635 - val_accuracy: 0.9833 - val_loss: 0.0484\n",
      "Epoch 185/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9856 - loss: 0.0632 - val_accuracy: 0.9833 - val_loss: 0.0484\n",
      "Epoch 186/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0631 - val_accuracy: 0.9833 - val_loss: 0.0482\n",
      "Epoch 187/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9856 - loss: 0.0628 - val_accuracy: 0.9833 - val_loss: 0.0480\n",
      "Epoch 188/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9856 - loss: 0.0626 - val_accuracy: 0.9833 - val_loss: 0.0478\n",
      "Epoch 189/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0624 - val_accuracy: 0.9833 - val_loss: 0.0478\n",
      "Epoch 190/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0622 - val_accuracy: 0.9750 - val_loss: 0.0476\n",
      "Epoch 191/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0620 - val_accuracy: 0.9750 - val_loss: 0.0476\n",
      "Epoch 192/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0619 - val_accuracy: 0.9750 - val_loss: 0.0474\n",
      "Epoch 193/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0616 - val_accuracy: 0.9833 - val_loss: 0.0475\n",
      "Epoch 194/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9856 - loss: 0.0613 - val_accuracy: 0.9833 - val_loss: 0.0473\n",
      "Epoch 195/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9856 - loss: 0.0611 - val_accuracy: 0.9833 - val_loss: 0.0471\n",
      "Epoch 196/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9856 - loss: 0.0609 - val_accuracy: 0.9833 - val_loss: 0.0471\n",
      "Epoch 197/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0606 - val_accuracy: 0.9833 - val_loss: 0.0470\n",
      "Epoch 198/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9856 - loss: 0.0605 - val_accuracy: 0.9833 - val_loss: 0.0469\n",
      "Epoch 199/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9892 - loss: 0.0602 - val_accuracy: 0.9833 - val_loss: 0.0467\n",
      "Epoch 200/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0600 - val_accuracy: 0.9833 - val_loss: 0.0465\n",
      "Epoch 201/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9892 - loss: 0.0598 - val_accuracy: 0.9833 - val_loss: 0.0466\n",
      "Epoch 202/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9892 - loss: 0.0596 - val_accuracy: 0.9833 - val_loss: 0.0464\n",
      "Epoch 203/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0595 - val_accuracy: 0.9833 - val_loss: 0.0463\n",
      "Epoch 204/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9892 - loss: 0.0593 - val_accuracy: 0.9833 - val_loss: 0.0463\n",
      "Epoch 205/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0590 - val_accuracy: 0.9833 - val_loss: 0.0462\n",
      "Epoch 206/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0588 - val_accuracy: 0.9833 - val_loss: 0.0461\n",
      "Epoch 207/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9892 - loss: 0.0587 - val_accuracy: 0.9833 - val_loss: 0.0459\n",
      "Epoch 208/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0585 - val_accuracy: 0.9833 - val_loss: 0.0457\n",
      "Epoch 209/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0583 - val_accuracy: 0.9750 - val_loss: 0.0457\n",
      "Epoch 210/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0581 - val_accuracy: 0.9750 - val_loss: 0.0455\n",
      "Epoch 211/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9856 - loss: 0.0580 - val_accuracy: 0.9750 - val_loss: 0.0454\n",
      "Epoch 212/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9856 - loss: 0.0578 - val_accuracy: 0.9750 - val_loss: 0.0452\n",
      "Epoch 213/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9856 - loss: 0.0576 - val_accuracy: 0.9750 - val_loss: 0.0451\n",
      "Epoch 214/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9856 - loss: 0.0574 - val_accuracy: 0.9750 - val_loss: 0.0450\n",
      "Epoch 215/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0573 - val_accuracy: 0.9750 - val_loss: 0.0449\n",
      "Epoch 216/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0571 - val_accuracy: 0.9750 - val_loss: 0.0447\n",
      "Epoch 217/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9856 - loss: 0.0570 - val_accuracy: 0.9750 - val_loss: 0.0445\n",
      "Epoch 218/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0568 - val_accuracy: 0.9750 - val_loss: 0.0444\n",
      "Epoch 219/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0566 - val_accuracy: 0.9750 - val_loss: 0.0442\n",
      "Epoch 220/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0564 - val_accuracy: 0.9750 - val_loss: 0.0443\n",
      "Epoch 221/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0562 - val_accuracy: 0.9833 - val_loss: 0.0444\n",
      "Epoch 222/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0559 - val_accuracy: 0.9833 - val_loss: 0.0445\n",
      "Epoch 223/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0558 - val_accuracy: 0.9833 - val_loss: 0.0443\n",
      "Epoch 224/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9892 - loss: 0.0555 - val_accuracy: 0.9750 - val_loss: 0.0443\n",
      "Epoch 225/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0554 - val_accuracy: 0.9833 - val_loss: 0.0441\n",
      "Epoch 226/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9892 - loss: 0.0552 - val_accuracy: 0.9833 - val_loss: 0.0439\n",
      "Epoch 227/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9892 - loss: 0.0550 - val_accuracy: 0.9833 - val_loss: 0.0438\n",
      "Epoch 228/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9892 - loss: 0.0548 - val_accuracy: 0.9833 - val_loss: 0.0437\n",
      "Epoch 229/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0547 - val_accuracy: 0.9750 - val_loss: 0.0436\n",
      "Epoch 230/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0544 - val_accuracy: 0.9750 - val_loss: 0.0437\n",
      "Epoch 231/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0543 - val_accuracy: 0.9750 - val_loss: 0.0436\n",
      "Epoch 232/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9892 - loss: 0.0541 - val_accuracy: 0.9750 - val_loss: 0.0435\n",
      "Epoch 233/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0539 - val_accuracy: 0.9750 - val_loss: 0.0433\n",
      "Epoch 234/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0537 - val_accuracy: 0.9750 - val_loss: 0.0432\n",
      "Epoch 235/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0535 - val_accuracy: 0.9750 - val_loss: 0.0430\n",
      "Epoch 236/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0534 - val_accuracy: 0.9750 - val_loss: 0.0430\n",
      "Epoch 237/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0532 - val_accuracy: 0.9750 - val_loss: 0.0429\n",
      "Epoch 238/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0530 - val_accuracy: 0.9750 - val_loss: 0.0429\n",
      "Epoch 239/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0529 - val_accuracy: 0.9750 - val_loss: 0.0427\n",
      "Epoch 240/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0527 - val_accuracy: 0.9750 - val_loss: 0.0426\n",
      "Epoch 241/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9892 - loss: 0.0526 - val_accuracy: 0.9750 - val_loss: 0.0427\n",
      "Epoch 242/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9892 - loss: 0.0524 - val_accuracy: 0.9750 - val_loss: 0.0425\n",
      "Epoch 243/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9892 - loss: 0.0523 - val_accuracy: 0.9750 - val_loss: 0.0424\n",
      "Epoch 244/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0521 - val_accuracy: 0.9750 - val_loss: 0.0422\n",
      "Epoch 245/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0519 - val_accuracy: 0.9750 - val_loss: 0.0420\n",
      "Epoch 246/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0518 - val_accuracy: 0.9750 - val_loss: 0.0421\n",
      "Epoch 247/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9892 - loss: 0.0518 - val_accuracy: 0.9750 - val_loss: 0.0420\n",
      "Epoch 248/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9892 - loss: 0.0515 - val_accuracy: 0.9750 - val_loss: 0.0419\n",
      "Epoch 249/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0514 - val_accuracy: 0.9750 - val_loss: 0.0420\n",
      "Epoch 250/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0512 - val_accuracy: 0.9750 - val_loss: 0.0419\n",
      "Epoch 251/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9892 - loss: 0.0510 - val_accuracy: 0.9750 - val_loss: 0.0418\n",
      "Epoch 252/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9892 - loss: 0.0508 - val_accuracy: 0.9750 - val_loss: 0.0420\n",
      "Epoch 253/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0507 - val_accuracy: 0.9833 - val_loss: 0.0419\n",
      "Epoch 254/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0506 - val_accuracy: 0.9750 - val_loss: 0.0418\n",
      "Epoch 255/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0504 - val_accuracy: 0.9750 - val_loss: 0.0416\n",
      "Epoch 256/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0502 - val_accuracy: 0.9750 - val_loss: 0.0413\n",
      "Epoch 257/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9892 - loss: 0.0501 - val_accuracy: 0.9750 - val_loss: 0.0412\n",
      "Epoch 258/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0499 - val_accuracy: 0.9750 - val_loss: 0.0411\n",
      "Epoch 259/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9892 - loss: 0.0498 - val_accuracy: 0.9750 - val_loss: 0.0413\n",
      "Epoch 260/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9892 - loss: 0.0496 - val_accuracy: 0.9750 - val_loss: 0.0413\n",
      "Epoch 261/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9892 - loss: 0.0494 - val_accuracy: 0.9750 - val_loss: 0.0412\n",
      "Epoch 262/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0493 - val_accuracy: 0.9750 - val_loss: 0.0412\n",
      "Epoch 263/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0491 - val_accuracy: 0.9750 - val_loss: 0.0411\n",
      "Epoch 264/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0490 - val_accuracy: 0.9750 - val_loss: 0.0412\n",
      "Epoch 265/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0489 - val_accuracy: 0.9750 - val_loss: 0.0412\n",
      "Epoch 266/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0487 - val_accuracy: 0.9750 - val_loss: 0.0412\n",
      "Epoch 267/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9892 - loss: 0.0486 - val_accuracy: 0.9750 - val_loss: 0.0410\n",
      "Epoch 268/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0484 - val_accuracy: 0.9750 - val_loss: 0.0409\n",
      "Epoch 269/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0483 - val_accuracy: 0.9750 - val_loss: 0.0409\n",
      "Epoch 270/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0482 - val_accuracy: 0.9750 - val_loss: 0.0407\n",
      "Epoch 271/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9892 - loss: 0.0480 - val_accuracy: 0.9750 - val_loss: 0.0406\n",
      "Epoch 272/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0479 - val_accuracy: 0.9750 - val_loss: 0.0406\n",
      "Epoch 273/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9892 - loss: 0.0477 - val_accuracy: 0.9750 - val_loss: 0.0406\n",
      "Epoch 274/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9892 - loss: 0.0476 - val_accuracy: 0.9750 - val_loss: 0.0406\n",
      "Epoch 275/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0474 - val_accuracy: 0.9750 - val_loss: 0.0405\n",
      "Epoch 276/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9892 - loss: 0.0473 - val_accuracy: 0.9750 - val_loss: 0.0405\n",
      "Epoch 277/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0472 - val_accuracy: 0.9750 - val_loss: 0.0404\n",
      "Epoch 278/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9892 - loss: 0.0471 - val_accuracy: 0.9750 - val_loss: 0.0402\n",
      "Epoch 279/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0470 - val_accuracy: 0.9750 - val_loss: 0.0402\n",
      "Epoch 280/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0469 - val_accuracy: 0.9750 - val_loss: 0.0402\n",
      "Epoch 281/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0467 - val_accuracy: 0.9750 - val_loss: 0.0400\n",
      "Epoch 282/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9892 - loss: 0.0466 - val_accuracy: 0.9750 - val_loss: 0.0399\n",
      "Epoch 283/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0465 - val_accuracy: 0.9750 - val_loss: 0.0398\n",
      "Epoch 284/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9892 - loss: 0.0464 - val_accuracy: 0.9750 - val_loss: 0.0398\n",
      "Epoch 285/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9892 - loss: 0.0462 - val_accuracy: 0.9750 - val_loss: 0.0400\n",
      "Epoch 286/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9892 - loss: 0.0461 - val_accuracy: 0.9750 - val_loss: 0.0399\n",
      "Epoch 287/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0460 - val_accuracy: 0.9750 - val_loss: 0.0398\n",
      "Epoch 288/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9892 - loss: 0.0458 - val_accuracy: 0.9750 - val_loss: 0.0397\n",
      "Epoch 289/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9892 - loss: 0.0457 - val_accuracy: 0.9750 - val_loss: 0.0397\n",
      "Epoch 290/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9892 - loss: 0.0455 - val_accuracy: 0.9750 - val_loss: 0.0397\n",
      "Epoch 291/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9892 - loss: 0.0454 - val_accuracy: 0.9750 - val_loss: 0.0396\n",
      "Epoch 292/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9892 - loss: 0.0453 - val_accuracy: 0.9750 - val_loss: 0.0397\n",
      "Epoch 293/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9892 - loss: 0.0451 - val_accuracy: 0.9750 - val_loss: 0.0396\n",
      "Epoch 294/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9892 - loss: 0.0450 - val_accuracy: 0.9750 - val_loss: 0.0395\n",
      "Epoch 295/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9892 - loss: 0.0449 - val_accuracy: 0.9750 - val_loss: 0.0396\n",
      "Epoch 296/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9892 - loss: 0.0448 - val_accuracy: 0.9750 - val_loss: 0.0396\n",
      "Epoch 297/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9892 - loss: 0.0446 - val_accuracy: 0.9750 - val_loss: 0.0395\n",
      "Epoch 298/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9892 - loss: 0.0445 - val_accuracy: 0.9750 - val_loss: 0.0396\n",
      "Epoch 299/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9892 - loss: 0.0444 - val_accuracy: 0.9750 - val_loss: 0.0394\n",
      "Epoch 300/300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9892 - loss: 0.0443 - val_accuracy: 0.9833 - val_loss: 0.0396\n",
      "\n",
      "MLP Results:\n",
      "Training time: 27.14 seconds\n",
      "Training accuracy: 98.74%\n",
      "Testing accuracy: 97.08%\n",
      "Expected test accuracy (from paper): ~99.04%\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Hyper-parameters from paper\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-2\n",
    "EPOCHS = 3000\n",
    "NUM_NODES = [500, 500, 500]\n",
    "NUM_CLASSES = 2\n",
    "TEST_SIZE = 0.30\n",
    "\n",
    "# Load data\n",
    "X, y = datasets.load_breast_cancer(return_X_y=True)\n",
    "\n",
    "# Split (stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, stratify=y, random_state=SEED\n",
    ")\n",
    "\n",
    "# Standardize features: fit on train only\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Build model\n",
    "mlp_model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(X_train_scaled.shape[1],)),\n",
    "        layers.Dense(NUM_NODES[0], activation=\"relu\", name=\"hidden_layer_1\"),\n",
    "        layers.Dense(NUM_NODES[1], activation=\"relu\", name=\"hidden_layer_2\"),\n",
    "        layers.Dense(NUM_NODES[2], activation=\"relu\", name=\"hidden_layer_3\"),\n",
    "        layers.Dense(NUM_CLASSES, activation=\"softmax\", name=\"output_layer\"),\n",
    "    ],\n",
    "    name=\"mlp_500_500_500\",\n",
    ")\n",
    "\n",
    "# Compile: SGD with lr=1e-2 (plain SGD, no momentum to match paper unless paper used momentum)\n",
    "optimizer = keras.optimizers.SGD(learning_rate=LEARNING_RATE)\n",
    "mlp_model.compile(optimizer=optimizer,\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "mlp_model.summary()\n",
    "\n",
    "# Train. If you want to monitor test set, pass validation_data\n",
    "start = time.time()\n",
    "history = mlp_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_test_scaled, y_test),\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    ")\n",
    "train_time = time.time() - start\n",
    "\n",
    "# Evaluate\n",
    "train_loss, train_acc = mlp_model.evaluate(X_train_scaled, y_train, verbose=0)\n",
    "test_loss, test_acc = mlp_model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "\n",
    "print(\"\\nMLP Results:\")\n",
    "print(f\"Training time: {train_time:.2f} seconds\")\n",
    "print(f\"Training accuracy: {train_acc*100:.4f}%\")\n",
    "print(f\"Testing accuracy:  {test_acc*100:.4f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
